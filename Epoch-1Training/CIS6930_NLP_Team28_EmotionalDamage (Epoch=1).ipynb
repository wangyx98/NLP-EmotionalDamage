{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORgmwobm4_g2"
      },
      "source": [
        "# Load dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrMTeAyDlOBQ"
      },
      "source": [
        "## Go to the dataset directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64uskL5n_Vzk",
        "outputId": "36e9e97e-de23-4b52-f7b8-0fd46b9361fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'dataset/'\n",
            "/content\n",
            "sample_data\n"
          ]
        }
      ],
      "source": [
        "%cd dataset/\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSYmlicmmRKy"
      },
      "source": [
        "## Import the pandas library and perform data reading for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UZm7nLTKmfdz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('train.csv', sep='\\t', header=None)\n",
        "test = pd.read_csv('test.csv', sep='\\t', header=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIn3DaU_mm7s"
      },
      "source": [
        "## Adding column names to data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oUnLTl9Nmxd1"
      },
      "outputs": [],
      "source": [
        "train.columns = [\"text\",'labels']\n",
        "test.columns = [\"text\",'labels']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWslftXjm08j"
      },
      "source": [
        "## The first 10 texts of the training set are read in the format \"text, labels\". The labels may contain multiple sentiment categories, each sentiment is separated by ','."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "eZwM1noTnqph",
        "outputId": "9f63e31e-67f2-47f2-ab85-906053e9c0df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text labels\n",
              "0  My favourite food is anything I didn't have to...     27\n",
              "1  Now if he does off himself, everyone will thin...     27\n",
              "2                     WHY THE FUCK IS BAYLESS ISOING      2\n",
              "3                        To make her feel threatened     14\n",
              "4                             Dirty Southern Wankers      3\n",
              "5  OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe...     26\n",
              "6  Yes I heard abt the f bombs! That has to be wh...     15\n",
              "7  We need more boards and to create a bit more s...   8,20\n",
              "8  Damn youtube and outrage drama is super lucrat...      0\n",
              "9  It might be linked to the trust factor of your...     27"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df3ef45b-03e9-4e4b-9271-04c96e2405b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My favourite food is anything I didn't have to...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Now if he does off himself, everyone will thin...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>To make her feel threatened</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dirty Southern Wankers</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Yes I heard abt the f bombs! That has to be wh...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>We need more boards and to create a bit more s...</td>\n",
              "      <td>8,20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Damn youtube and outrage drama is super lucrat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>It might be linked to the trust factor of your...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df3ef45b-03e9-4e4b-9271-04c96e2405b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df3ef45b-03e9-4e4b-9271-04c96e2405b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df3ef45b-03e9-4e4b-9271-04c96e2405b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "foY1dbLhn3nG",
        "outputId": "aded24be-5d4e-4e5f-9485-34d655a6c09a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text labels\n",
              "0  I’m really sorry about your situation :( Altho...     25\n",
              "1    It's wonderful because it's awful. At not with.      0\n",
              "2  Kings fan here, good luck to you guys! Will be...     13\n",
              "3  I didn't know that, thank you for teaching me ...     15\n",
              "4  They got bored from haunting earth for thousan...     27\n",
              "5  Thank you for asking questions and recognizing...     15\n",
              "6                                     You’re welcome     15\n",
              "7                    100%! Congrats on your job too!     15\n",
              "8  I’m sorry to hear that friend :(. It’s for the...     24\n",
              "9   Girlfriend weak as well, that jump was pathetic.     25"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16ddbf43-f4a8-4700-bc00-472f21282270\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I’m really sorry about your situation :( Altho...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It's wonderful because it's awful. At not with.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kings fan here, good luck to you guys! Will be...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I didn't know that, thank you for teaching me ...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>They got bored from haunting earth for thousan...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Thank you for asking questions and recognizing...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>You’re welcome</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>100%! Congrats on your job too!</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I’m sorry to hear that friend :(. It’s for the...</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Girlfriend weak as well, that jump was pathetic.</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16ddbf43-f4a8-4700-bc00-472f21282270')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16ddbf43-f4a8-4700-bc00-472f21282270 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16ddbf43-f4a8-4700-bc00-472f21282270');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "test.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHfWI95Tq3d7"
      },
      "source": [
        "# Install and import related libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWpIE-2jq8f-",
        "outputId": "086d358e-0c80-4cb4-8283-2862ed86ae85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting paddlenlp\n",
            "  Downloading paddlenlp-2.5.2-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Flask-Babel<3.0.0\n",
            "  Downloading Flask_Babel-2.0.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting paddlefsl\n",
            "  Downloading paddlefsl-1.1.0-py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.0/101.0 KB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting paddle2onnx\n",
            "  Downloading paddle2onnx-1.0.6-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer in /usr/local/lib/python3.9/dist-packages (from paddlenlp) (0.7.0)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.95.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 KB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting datasets>=2.0.0\n",
            "  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 KB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from paddlenlp) (4.65.0)\n",
            "Collecting multiprocess<=0.70.12.2\n",
            "  Downloading multiprocess-0.70.12.2-py39-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 KB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting visualdl\n",
            "  Downloading visualdl-2.5.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.9/dist-packages (from paddlenlp) (0.42.1)\n",
            "Collecting dill<0.3.5\n",
            "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 KB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich in /usr/local/lib/python3.9/dist-packages (from paddlenlp) (13.3.3)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.21.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.11.1\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->paddlenlp) (23.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->paddlenlp) (6.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->paddlenlp) (9.0.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->paddlenlp) (2.27.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->paddlenlp) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->paddlenlp) (1.22.4)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->paddlenlp) (2023.3.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.9/dist-packages (from Flask-Babel<3.0.0->paddlenlp) (2022.7.1)\n",
            "Requirement already satisfied: Babel>=2.3 in /usr/local/lib/python3.9/dist-packages (from Flask-Babel<3.0.0->paddlenlp) (2.12.1)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.9/dist-packages (from Flask-Babel<3.0.0->paddlenlp) (2.2.3)\n",
            "Requirement already satisfied: Jinja2>=2.5 in /usr/local/lib/python3.9/dist-packages (from Flask-Babel<3.0.0->paddlenlp) (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.11.1->paddlenlp) (3.10.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.11.1->paddlenlp) (4.5.0)\n",
            "Collecting starlette<0.27.0,>=0.26.1\n",
            "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.9/dist-packages (from fastapi->paddlenlp) (1.10.7)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from rich->paddlenlp) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from rich->paddlenlp) (2.14.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.9/dist-packages (from seqeval->paddlenlp) (1.2.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer->paddlenlp) (8.1.3)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rarfile\n",
            "  Downloading rarfile-4.0-py3-none-any.whl (28 kB)\n",
            "Collecting x2paddle\n",
            "  Downloading x2paddle-1.4.1-py3-none-any.whl (316 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.2/316.2 KB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tritonclient[all]\n",
            "  Downloading tritonclient-2.32.0-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting attrdict\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Collecting onnx>=1.6.0\n",
            "  Downloading onnx-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.0.0 in /usr/local/lib/python3.9/dist-packages (from visualdl->paddlenlp) (8.4.0)\n",
            "Collecting visualdl\n",
            "  Downloading visualdl-2.5.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from visualdl->paddlenlp) (1.16.0)\n",
            "  Downloading visualdl-2.4.2-py3-none-any.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.11.0 in /usr/local/lib/python3.9/dist-packages (from visualdl->paddlenlp) (3.20.3)\n",
            "Collecting bce-python-sdk\n",
            "  Downloading bce_python_sdk-0.8.83-py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.5/210.5 KB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from visualdl->paddlenlp) (3.7.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.9/dist-packages (from Flask->Flask-Babel<3.0.0->paddlenlp) (2.1.2)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.9/dist-packages (from Flask->Flask-Babel<3.0.0->paddlenlp) (2.2.3)\n",
            "Requirement already satisfied: importlib-metadata>=3.6.0 in /usr/local/lib/python3.9/dist-packages (from Flask->Flask-Babel<3.0.0->paddlenlp) (6.1.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (22.2.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2>=2.5->Flask-Babel<3.0.0->paddlenlp) (2.1.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->paddlenlp) (0.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (2022.12.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.1.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.10.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.9/dist-packages (from starlette<0.27.0,>=0.26.1->fastapi->paddlenlp) (3.6.2)\n",
            "Requirement already satisfied: future>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.3)\n",
            "Collecting pycryptodome>=3.8.0\n",
            "  Downloading pycryptodome-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->visualdl->paddlenlp) (1.4.4)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->visualdl->paddlenlp) (5.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->visualdl->paddlenlp) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->visualdl->paddlenlp) (0.11.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->visualdl->paddlenlp) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->visualdl->paddlenlp) (4.39.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->visualdl->paddlenlp) (2.8.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.9/dist-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi->paddlenlp) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6.0->Flask->Flask-Babel<3.0.0->paddlenlp) (3.15.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=411c9b4b478c3345965a5336b21d731a704c4de1f50e80e6aa7c40250e990234\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/a5/92/2c80d1928733611c2747a9820e1324a6835524d9411510c142\n",
            "Successfully built seqeval\n",
            "Installing collected packages: sentencepiece, paddle2onnx, xxhash, pycryptodome, multidict, h11, frozenlist, dill, colorlog, colorama, async-timeout, yarl, uvicorn, starlette, responses, paddlefsl, multiprocess, huggingface-hub, bce-python-sdk, aiosignal, seqeval, Flask-Babel, fastapi, aiohttp, visualdl, datasets, paddlenlp\n",
            "Successfully installed Flask-Babel-2.0.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 bce-python-sdk-0.8.83 colorama-0.4.6 colorlog-6.7.0 datasets-2.11.0 dill-0.3.4 fastapi-0.95.0 frozenlist-1.3.3 h11-0.14.0 huggingface-hub-0.13.3 multidict-6.0.4 multiprocess-0.70.12.2 paddle2onnx-1.0.6 paddlefsl-1.1.0 paddlenlp-2.5.2 pycryptodome-3.17 responses-0.18.0 sentencepiece-0.1.97 seqeval-1.2.2 starlette-0.26.1 uvicorn-0.21.1 visualdl-2.4.2 xxhash-3.2.0 yarl-1.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade paddlenlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "herF3Q2qrfVf",
        "outputId": "ff5701b0-f4ec-49fa-fb34-6fbc0c05da1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting paddlepaddle\n",
            "  Downloading paddlepaddle-2.4.2-cp39-cp39-manylinux1_x86_64.whl (121.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.7/121.7 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting paddle-bfloat==0.1.7\n",
            "  Downloading paddle_bfloat-0.1.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (383 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.1/383.1 KB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from paddlepaddle) (8.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from paddlepaddle) (4.4.2)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.9/dist-packages (from paddlepaddle) (2.27.1)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.9/dist-packages (from paddlepaddle) (3.3.0)\n",
            "Collecting protobuf<=3.20.0,>=3.1.0\n",
            "  Downloading protobuf-3.20.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting astor\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.9/dist-packages (from paddlepaddle) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from paddlepaddle) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20.0->paddlepaddle) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20.0->paddlepaddle) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20.0->paddlepaddle) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20.0->paddlepaddle) (1.26.15)\n",
            "Installing collected packages: paddle-bfloat, protobuf, astor, paddlepaddle\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n",
            "googleapis-common-protos 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-translate 3.8.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-language 2.6.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-firestore 2.7.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-datastore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery 3.4.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.19.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed astor-0.8.1 paddle-bfloat-0.1.7 paddlepaddle-2.4.2 protobuf-3.20.0\n"
          ]
        }
      ],
      "source": [
        "!pip install paddlepaddle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "X7YvSrZprIz3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import paddle\n",
        "import paddlenlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fafm1FtVsfGY"
      },
      "source": [
        "# Data pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0jIHcPbsiIz"
      },
      "source": [
        "## For the 28 micro-sentiment multi-label classification scenario, where a sentence may correspond to multiple sentiment category labels, the sentiment labels of the dataset need to be transformed using One-Hot coding first, with \"0\" indicating absence and \"1\" indicating presence for each sentiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTPiTK0pstvz"
      },
      "source": [
        "### Create sentiment label mapping relationships."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XQmitCV3tNrx"
      },
      "outputs": [],
      "source": [
        "label_vocab = {\n",
        "    0: \"admiration\",\n",
        "    1: \"amusement\",\n",
        "    2: \"anger\",\n",
        "    3: \"annoyance\",\n",
        "    4: \"approval\",\n",
        "    5: \"caring\",\n",
        "    6: \"confusion\",\n",
        "    7: \"curiosity\",\n",
        "    8: \"desire\",\n",
        "    9: \"disappointment\",\n",
        "    10: \"disapproval\",\n",
        "    11: \"disgust\",\n",
        "    12: \"embarrassment\",\n",
        "    13: \"excitement\",\n",
        "    14: \"fear\",\n",
        "    15: \"gratitude\",\n",
        "    16: \"grief\",\n",
        "    17: \"joy\",\n",
        "    18: \"love\",\n",
        "    19: \"nervousness\",\n",
        "    20: \"optimism\",\n",
        "    21: \"pride\",\n",
        "    22: \"realization\",\n",
        "    23: \"relief\",\n",
        "    24: \"remorse\",\n",
        "    25: \"sadness\",\n",
        "    26: \"surprise\",\n",
        "    27: \"neutral\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-EcFAvotT5Q"
      },
      "source": [
        "### Customize the dataset, read the data file, create the dataset and define the data type as MapDataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FhHKTcR7t3Xq"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "from paddlenlp.datasets import load_dataset\n",
        "\n",
        "# Clear invalid characters\n",
        "def clean_text(text):\n",
        "    text = text.replace(\"\\r\", \"\").replace(\"\\n\", \"\")\n",
        "    text = re.sub(r\"\\\\n\\n\", \".\", text)\n",
        "    return text\n",
        "\n",
        "# Define the read data set function\n",
        "def read_custom_data(filepath, is_one_hot=True):\n",
        "    f = open(filepath)\n",
        "    while True:\n",
        "        line = f.readline()\n",
        "        if not line:\n",
        "            break\n",
        "        data = line.strip().split('\\t')\n",
        "        # One-hot processing for 28 types of micro sentiment tags\n",
        "        if is_one_hot:\n",
        "            labels = [float(1) if str(i) in data[1].split(',') else float(0) for i in range(28)]  # 28 types\n",
        "        else:\n",
        "            labels = [int(d) for d in data[1].split(',')]\n",
        "        yield {\"text\": clean_text(data[0]), \"labels\": labels}\n",
        "    f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "M_SQ3JwruQSe"
      },
      "outputs": [],
      "source": [
        "# load_dataset() to Create dataset.\n",
        "# lazy=False，The dataset is returned as a MapDataset type.\n",
        "# Pre-processing of training and validation sets.\n",
        "train_ds = load_dataset(read_custom_data, filepath='train.csv', lazy=False) \n",
        "test_ds = load_dataset(read_custom_data, filepath='test.csv', lazy=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9nrlxqJwCQq"
      },
      "source": [
        "### Print dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bExeME40wGuv",
        "outputId": "b8ebe161-e02a-4306-e60f-df00b2b99b44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datatype: <class 'paddlenlp.datasets.dataset.MapDataset'>\n",
            "training dataset example: {'text': \"My favourite food is anything I didn't have to cook myself.\", 'labels': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}\n",
            "testing dataset example: {'text': 'I’m really sorry about your situation :( Although I love the names Sapphira, Cirilla, and Scarlett!', 'labels': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}\n"
          ]
        }
      ],
      "source": [
        "print(\"datatype:\", type(train_ds))\n",
        "print(\"training dataset example:\", train_ds[0])\n",
        "print(\"testing dataset example:\", test_ds[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEqnn-WG4Pa2"
      },
      "source": [
        "## Load Chinese ERNIE 3.0 pre-training model and word splitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8f0bb537306940a192c374f5458f3c99",
            "9d6f5d91a6c34eb2be6c43b9d77316c2",
            "5a0a3265f4fc40acac71a85fc3a29c97",
            "5f302f73d14d4aa68d48a8d06c4d8717",
            "3f2a18e109734e53bd330eceb3d79712",
            "d0b878e93f3b4a2a9b3de57d15ab55e1",
            "6d0f814a0b03493abe1044ef14bf15dc",
            "23288bf360984ed182be7d6d84841716",
            "ce8f3f6b29f74c94aedc579412a4aa5e",
            "5269406c713340ceb8f6bd40782769d7",
            "74a0ab1a08ee49cba9f797176a92b2f2",
            "6bcd679979a14b92ad7bd28b58ed883f",
            "ac8d5f80a0324c538908ab32974f9b6a",
            "751c62037368473dac02b36dd1c0b05f",
            "6e257f83475345ddbed64f81dccfb309",
            "290bc213ab9e48898ebbc8c4e31fe36e",
            "94803e83cafa4a50bb2d8a3fbaf73274",
            "faa019ca3caa4a4e809a1612319ac503",
            "36f1a68b633d45c08eb1fc80d282838d",
            "62335350a40e41d1b1fe80e221baa984",
            "ef7240d1bccd40ebbd05455bb4c994bf",
            "d79c404107ff4d16a3945df9b74ec5d3"
          ]
        },
        "id": "4dJq6b6D4L-w",
        "outputId": "f5de5d1e-4388-4282-dbf6-c671a9320125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 20:21:59,659] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.ernie.modeling.ErnieForSequenceClassification'> to load 'ernie-3.0-medium-zh'.\u001b[0m\n",
            "\u001b[32m[2023-04-04 20:21:59,662] [    INFO]\u001b[0m - Model config ErnieConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"enable_recompute\": false,\n",
            "  \"fuse\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\",\n",
            "    \"8\": \"LABEL_8\",\n",
            "    \"9\": \"LABEL_9\",\n",
            "    \"10\": \"LABEL_10\",\n",
            "    \"11\": \"LABEL_11\",\n",
            "    \"12\": \"LABEL_12\",\n",
            "    \"13\": \"LABEL_13\",\n",
            "    \"14\": \"LABEL_14\",\n",
            "    \"15\": \"LABEL_15\",\n",
            "    \"16\": \"LABEL_16\",\n",
            "    \"17\": \"LABEL_17\",\n",
            "    \"18\": \"LABEL_18\",\n",
            "    \"19\": \"LABEL_19\",\n",
            "    \"20\": \"LABEL_20\",\n",
            "    \"21\": \"LABEL_21\",\n",
            "    \"22\": \"LABEL_22\",\n",
            "    \"23\": \"LABEL_23\",\n",
            "    \"24\": \"LABEL_24\",\n",
            "    \"25\": \"LABEL_25\",\n",
            "    \"26\": \"LABEL_26\",\n",
            "    \"27\": \"LABEL_27\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_10\": 10,\n",
            "    \"LABEL_11\": 11,\n",
            "    \"LABEL_12\": 12,\n",
            "    \"LABEL_13\": 13,\n",
            "    \"LABEL_14\": 14,\n",
            "    \"LABEL_15\": 15,\n",
            "    \"LABEL_16\": 16,\n",
            "    \"LABEL_17\": 17,\n",
            "    \"LABEL_18\": 18,\n",
            "    \"LABEL_19\": 19,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_20\": 20,\n",
            "    \"LABEL_21\": 21,\n",
            "    \"LABEL_22\": 22,\n",
            "    \"LABEL_23\": 23,\n",
            "    \"LABEL_24\": 24,\n",
            "    \"LABEL_25\": 25,\n",
            "    \"LABEL_26\": 26,\n",
            "    \"LABEL_27\": 27,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_7\": 7,\n",
            "    \"LABEL_8\": 8,\n",
            "    \"LABEL_9\": 9\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"ernie\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"paddlenlp_version\": null,\n",
            "  \"pool_act\": \"tanh\",\n",
            "  \"task_id\": 0,\n",
            "  \"task_type_vocab_size\": 16,\n",
            "  \"type_vocab_size\": 4,\n",
            "  \"use_task_id\": true,\n",
            "  \"vocab_size\": 40000\n",
            "}\n",
            "\u001b[0m\n",
            "\u001b[32m[2023-04-04 20:21:59,666] [    INFO]\u001b[0m - Configuration saved in /root/.paddlenlp/models/ernie-3.0-medium-zh/config.json\u001b[0m\n",
            "\u001b[32m[2023-04-04 20:21:59,668] [    INFO]\u001b[0m - Downloading ernie_3.0_medium_zh.pdparams from https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_medium_zh.pdparams\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/313M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f0bb537306940a192c374f5458f3c99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[33m[2023-04-04 20:22:31,192] [ WARNING]\u001b[0m - Some weights of the model checkpoint at ernie-3.0-medium-zh were not used when initializing ErnieForSequenceClassification: ['ernie.encoder.layers.6.linear1.weight', 'ernie.encoder.layers.6.norm1.bias', 'ernie.encoder.layers.6.norm2.bias', 'ernie.encoder.layers.6.linear1.bias', 'ernie.encoder.layers.6.self_attn.v_proj.weight', 'ernie.encoder.layers.6.norm1.weight', 'ernie.encoder.layers.6.self_attn.out_proj.bias', 'ernie.encoder.layers.6.self_attn.out_proj.weight', 'ernie.encoder.layers.6.norm2.weight', 'ernie.encoder.layers.6.self_attn.v_proj.bias', 'ernie.encoder.layers.6.linear2.bias', 'ernie.encoder.layers.6.self_attn.q_proj.bias', 'ernie.encoder.layers.6.self_attn.k_proj.weight', 'ernie.encoder.layers.6.linear2.weight', 'ernie.encoder.layers.6.self_attn.q_proj.weight', 'ernie.encoder.layers.6.self_attn.k_proj.bias']\n",
            "- This IS expected if you are initializing ErnieForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ErnieForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
            "\u001b[33m[2023-04-04 20:22:31,194] [ WARNING]\u001b[0m - Some weights of ErnieForSequenceClassification were not initialized from the model checkpoint at ernie-3.0-medium-zh and are newly initialized: ['classifier.weight', 'classifier.bias', 'ernie.pooler.dense.weight', 'ernie.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
            "\u001b[32m[2023-04-04 20:22:31,195] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load 'ernie-3.0-medium-zh'.\u001b[0m\n",
            "\u001b[32m[2023-04-04 20:22:31,196] [    INFO]\u001b[0m - Downloading https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_medium_zh_vocab.txt and saved to /root/.paddlenlp/models/ernie-3.0-medium-zh\u001b[0m\n",
            "\u001b[32m[2023-04-04 20:22:31,837] [    INFO]\u001b[0m - Downloading ernie_3.0_medium_zh_vocab.txt from https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_medium_zh_vocab.txt\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/182k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6bcd679979a14b92ad7bd28b58ed883f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 20:22:32,545] [    INFO]\u001b[0m - tokenizer config file saved in /root/.paddlenlp/models/ernie-3.0-medium-zh/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-04 20:22:32,548] [    INFO]\u001b[0m - Special tokens file saved in /root/.paddlenlp/models/ernie-3.0-medium-zh/special_tokens_map.json\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from paddlenlp.transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "model_name = \"ernie-3.0-medium-zh\"   # ERNIE3.0 model\n",
        "num_classes = 28  # 28 classification mission\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_classes=num_classes)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNHyEHEH5h7_"
      },
      "source": [
        "## Process the raw data into a model-acceptable format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gHk1B5Wc5tav"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import numpy as np\n",
        "\n",
        "from paddle.io import DataLoader, BatchSampler\n",
        "from paddlenlp.data import DataCollatorWithPadding\n",
        "\n",
        "# Data pre-processing function to convert text into integer sequences using a word splitter.\n",
        "def preprocess_function(examples, tokenizer, max_seq_length):\n",
        "    result = tokenizer(text=examples[\"text\"], max_seq_len=max_seq_length)\n",
        "    result[\"labels\"] = examples[\"labels\"]\n",
        "    return result\n",
        "\n",
        "trans_func = functools.partial(preprocess_function, tokenizer=tokenizer, max_seq_length=64)\n",
        "train_ds = train_ds.map(trans_func)\n",
        "test_ds = test_ds.map(trans_func)\n",
        "\n",
        "# function is constructed to extend the different length sequences to the maximum length of the data in the batch, and then stack the data.\n",
        "collate_fn = DataCollatorWithPadding(tokenizer)\n",
        "\n",
        "# Define the BatchSampler, select the batch size and whether to randomly jumble the DataLoader.\n",
        "train_batch_sampler = BatchSampler(train_ds, batch_size=32, shuffle=True)\n",
        "test_batch_sampler = BatchSampler(test_ds, batch_size=16, shuffle=False)\n",
        "train_data_loader = DataLoader(dataset=train_ds, batch_sampler=train_batch_sampler, collate_fn=collate_fn)\n",
        "test_data_loader = DataLoader(dataset=test_ds, batch_sampler=test_batch_sampler, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EPA9Lq97O_3"
      },
      "source": [
        "## Define model validation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7HLrZrzK7RdI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
        "from paddle.metric import Metric\n",
        "\n",
        "# Customize MultiLabelReport evaluation metrics.\n",
        "class MultiLabelReport(Metric):\n",
        "    \"\"\"\n",
        "    AUC and F1 Score for multi-label text classification task.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name='MultiLabelReport', average='micro'):\n",
        "        super(MultiLabelReport, self).__init__()\n",
        "        self.average = average\n",
        "        self._name = name\n",
        "        self.reset()\n",
        "\n",
        "    def f1_score(self, y_prob):\n",
        "        '''\n",
        "        Returns the f1 score by searching the best threshhold\n",
        "        '''\n",
        "        best_score = 0\n",
        "        for threshold in [i * 0.01 for i in range(100)]:\n",
        "            self.y_pred = y_prob > threshold\n",
        "            score = sklearn.metrics.f1_score(y_pred=self.y_pred, y_true=self.y_true, average=self.average)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                precison = precision_score(y_pred=self.y_pred, y_true=self.y_true, average=self.average)\n",
        "                recall = recall_score(y_pred=self.y_pred, y_true=self.y_true, average=self.average)\n",
        "        return best_score, precison, recall\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Resets all of the metric state.\n",
        "        \"\"\"\n",
        "        self.y_prob = None\n",
        "        self.y_true = None\n",
        "\n",
        "    def update(self, probs, labels):\n",
        "        if self.y_prob is not None:\n",
        "            self.y_prob = np.append(self.y_prob, probs.numpy(), axis=0)\n",
        "        else:\n",
        "            self.y_prob = probs.numpy()\n",
        "        if self.y_true is not None:\n",
        "            self.y_true = np.append(self.y_true, labels.numpy(), axis=0)\n",
        "        else:\n",
        "            self.y_true = labels.numpy()\n",
        "\n",
        "    def accumulate(self):\n",
        "        auc = roc_auc_score(\n",
        "            y_score=self.y_prob, y_true=self.y_true, average=self.average)\n",
        "        f1_score, precison, recall = self.f1_score(y_prob=self.y_prob)\n",
        "        return auc, f1_score, precison, recall\n",
        "\n",
        "    def name(self):\n",
        "        \"\"\"\n",
        "        Returns metric name\n",
        "        \"\"\"\n",
        "        return self._name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H04sxVsF7lwJ"
      },
      "source": [
        "# Building the training model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLbmmDC38F1l"
      },
      "source": [
        "## Select an optimization strategy and run configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9yvG7sEc8QZj"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import paddle.nn.functional as F\n",
        "\n",
        "# AdamW optimizer, cross-entropy loss function, custom MultiLabelReport evaluation metrics.\n",
        "optimizer = paddle.optimizer.AdamW(learning_rate=4e-5, parameters=model.parameters(), weight_decay=0.01)\n",
        "criterion = paddle.nn.BCEWithLogitsLoss()\n",
        "metric = MultiLabelReport()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evJ-MG798fyJ"
      },
      "source": [
        "## Model training and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "D_97el-H8hc7"
      },
      "outputs": [],
      "source": [
        "import paddle\n",
        "import numpy as np\n",
        "import paddle.nn.functional as F\n",
        "\n",
        "# Build the validation set evaluate function.\n",
        "@paddle.no_grad()\n",
        "def evaluate(model, criterion, metric, data_loader, label_vocab, if_return_results=True):\n",
        "    model.eval()\n",
        "    metric.reset()\n",
        "    losses = []\n",
        "    results = []\n",
        "    for batch in data_loader:\n",
        "        input_ids, token_type_ids, labels = batch['input_ids'], batch['token_type_ids'], batch['labels']\n",
        "        logits = model(input_ids, token_type_ids)\n",
        "        loss = criterion(logits, labels)\n",
        "        probs = F.sigmoid(logits)\n",
        "        losses.append(loss.numpy())\n",
        "        metric.update(probs, labels)\n",
        "        if if_return_results:\n",
        "            probs = probs.tolist()\n",
        "            for prob in probs:\n",
        "                result = []\n",
        "                for c, pred in enumerate(prob):\n",
        "                    if pred > 0.5:\n",
        "                        result.append(label_vocab[c])\n",
        "                results.append(','.join(result))\n",
        "\n",
        "    auc, f1_score, precison, recall = metric.accumulate()\n",
        "    print(\"eval loss: %.5f, auc: %.5f, f1 score: %.5f, precison: %.5f, recall: %.5f\" %\n",
        "          (np.mean(losses), auc, f1_score, precison, recall))\n",
        "    model.train()\n",
        "    metric.reset()\n",
        "    if if_return_results:\n",
        "        return results\n",
        "    else:\n",
        "        return f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8I8ToDtX87QQ",
        "outputId": "b05662b8-084b-448e-df2a-df0b705d6542"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "global step 10, epoch: 1, batch: 10, loss: 0.33754, auc: 0.65571, f1 score: 0.13641, speed: 0.21 step/s\n",
            "global step 20, epoch: 1, batch: 20, loss: 0.25342, auc: 0.64184, f1 score: 0.14700, speed: 0.16 step/s\n",
            "global step 30, epoch: 1, batch: 30, loss: 0.20112, auc: 0.64089, f1 score: 0.15463, speed: 0.15 step/s\n",
            "global step 40, epoch: 1, batch: 40, loss: 0.19831, auc: 0.63872, f1 score: 0.16452, speed: 0.13 step/s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[2023-04-04 20:30:47,734] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval loss: 0.18208, auc: 0.73445, f1 score: 0.30401, precison: 0.32928, recall: 0.28235\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[2023-04-04 20:30:48,290] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-04 20:30:48,292] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "global step 50, epoch: 1, batch: 50, loss: 0.17339, auc: 0.72086, f1 score: 0.30857, speed: 0.04 step/s\n",
            "global step 60, epoch: 1, batch: 60, loss: 0.15098, auc: 0.73460, f1 score: 0.32295, speed: 0.13 step/s\n",
            "global step 70, epoch: 1, batch: 70, loss: 0.17876, auc: 0.71199, f1 score: 0.29740, speed: 0.12 step/s\n",
            "global step 80, epoch: 1, batch: 80, loss: 0.13842, auc: 0.71968, f1 score: 0.30316, speed: 0.12 step/s\n",
            "eval loss: 0.15561, auc: 0.76600, f1 score: 0.30401, precison: 0.32928, recall: 0.28235\n",
            "global step 90, epoch: 1, batch: 90, loss: 0.15799, auc: 0.75483, f1 score: 0.32409, speed: 0.04 step/s\n",
            "global step 100, epoch: 1, batch: 100, loss: 0.15718, auc: 0.74465, f1 score: 0.30625, speed: 0.12 step/s\n",
            "global step 110, epoch: 1, batch: 110, loss: 0.13868, auc: 0.74672, f1 score: 0.30695, speed: 0.12 step/s\n",
            "global step 120, epoch: 1, batch: 120, loss: 0.17495, auc: 0.74934, f1 score: 0.30079, speed: 0.12 step/s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[2023-04-04 20:48:02,566] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval loss: 0.15056, auc: 0.77316, f1 score: 0.30606, precison: 0.33772, recall: 0.27982\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[2023-04-04 20:48:03,295] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-04 20:48:03,296] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "global step 130, epoch: 1, batch: 130, loss: 0.15766, auc: 0.75257, f1 score: 0.29971, speed: 0.04 step/s\n",
            "global step 140, epoch: 1, batch: 140, loss: 0.14728, auc: 0.75154, f1 score: 0.28075, speed: 0.12 step/s\n",
            "global step 150, epoch: 1, batch: 150, loss: 0.14153, auc: 0.76040, f1 score: 0.29590, speed: 0.12 step/s\n",
            "global step 160, epoch: 1, batch: 160, loss: 0.17781, auc: 0.76089, f1 score: 0.30347, speed: 0.12 step/s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[2023-04-04 20:56:48,285] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval loss: 0.14890, auc: 0.77547, f1 score: 0.30772, precison: 0.33832, recall: 0.28219\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[2023-04-04 20:56:48,977] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-04 20:56:48,979] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "global step 170, epoch: 1, batch: 170, loss: 0.16986, auc: 0.77681, f1 score: 0.31384, speed: 0.04 step/s\n",
            "global step 180, epoch: 1, batch: 180, loss: 0.13915, auc: 0.76576, f1 score: 0.31746, speed: 0.13 step/s\n",
            "global step 190, epoch: 1, batch: 190, loss: 0.16431, auc: 0.76885, f1 score: 0.31772, speed: 0.13 step/s\n",
            "global step 200, epoch: 1, batch: 200, loss: 0.14311, auc: 0.77278, f1 score: 0.32791, speed: 0.13 step/s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[2023-04-04 21:05:17,757] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval loss: 0.14350, auc: 0.78623, f1 score: 0.36949, precison: 0.48782, recall: 0.29736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[2023-04-04 21:05:18,433] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-04 21:05:18,435] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "global step 210, epoch: 1, batch: 210, loss: 0.14800, auc: 0.76599, f1 score: 0.31629, speed: 0.04 step/s\n",
            "global step 220, epoch: 1, batch: 220, loss: 0.15834, auc: 0.76740, f1 score: 0.31416, speed: 0.15 step/s\n",
            "global step 230, epoch: 1, batch: 230, loss: 0.13309, auc: 0.78510, f1 score: 0.34583, speed: 0.15 step/s\n",
            "global step 240, epoch: 1, batch: 240, loss: 0.15096, auc: 0.78880, f1 score: 0.35426, speed: 0.16 step/s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[2023-04-04 21:12:52,216] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval loss: 0.13819, auc: 0.80200, f1 score: 0.40715, precison: 0.44654, recall: 0.37415\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[2023-04-04 21:12:52,896] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-04 21:12:52,898] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "global step 250, epoch: 1, batch: 250, loss: 0.15684, auc: 0.77933, f1 score: 0.35457, speed: 0.04 step/s\n",
            "global step 260, epoch: 1, batch: 260, loss: 0.12024, auc: 0.80173, f1 score: 0.37830, speed: 0.15 step/s\n",
            "global step 270, epoch: 1, batch: 270, loss: 0.14096, auc: 0.80291, f1 score: 0.38551, speed: 0.15 step/s\n",
            "global step 280, epoch: 1, batch: 280, loss: 0.15655, auc: 0.80564, f1 score: 0.38850, speed: 0.15 step/s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[2023-04-04 21:20:32,890] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval loss: 0.13296, auc: 0.82497, f1 score: 0.41627, precison: 0.46253, recall: 0.37842\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[2023-04-04 21:20:33,574] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-04 21:20:33,576] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "global step 290, epoch: 1, batch: 290, loss: 0.14177, auc: 0.81551, f1 score: 0.40923, speed: 0.04 step/s\n",
            "global step 300, epoch: 1, batch: 300, loss: 0.13169, auc: 0.81531, f1 score: 0.39827, speed: 0.15 step/s\n",
            "global step 310, epoch: 1, batch: 310, loss: 0.12938, auc: 0.82140, f1 score: 0.40883, speed: 0.15 step/s\n",
            "global step 320, epoch: 1, batch: 320, loss: 0.14084, auc: 0.81763, f1 score: 0.41140, speed: 0.15 step/s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[2023-04-04 21:28:12,929] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval loss: 0.13045, auc: 0.83155, f1 score: 0.43621, precison: 0.49391, recall: 0.39058\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[2023-04-04 21:28:13,649] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-04 21:28:13,651] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "global step 330, epoch: 1, batch: 330, loss: 0.14036, auc: 0.83243, f1 score: 0.46505, speed: 0.04 step/s\n",
            "global step 340, epoch: 1, batch: 340, loss: 0.12461, auc: 0.82015, f1 score: 0.43323, speed: 0.15 step/s\n",
            "global step 350, epoch: 1, batch: 350, loss: 0.11652, auc: 0.82324, f1 score: 0.43191, speed: 0.15 step/s\n",
            "global step 360, epoch: 1, batch: 360, loss: 0.13061, auc: 0.82580, f1 score: 0.43514, speed: 0.15 step/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 21:35:52,087] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval loss: 0.12707, auc: 0.84128, f1 score: 0.45291, precison: 0.49924, recall: 0.41444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 21:35:52,816] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-04 21:35:52,818] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "global step 370, epoch: 1, batch: 370, loss: 0.14642, auc: 0.82629, f1 score: 0.41630, speed: 0.04 step/s\n",
            "global step 380, epoch: 1, batch: 380, loss: 0.13232, auc: 0.83236, f1 score: 0.42916, speed: 0.16 step/s\n",
            "global step 390, epoch: 1, batch: 390, loss: 0.12235, auc: 0.84059, f1 score: 0.43061, speed: 0.14 step/s\n",
            "global step 400, epoch: 1, batch: 400, loss: 0.13092, auc: 0.84429, f1 score: 0.42948, speed: 0.15 step/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 21:43:29,862] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval loss: 0.12421, auc: 0.85271, f1 score: 0.45974, precison: 0.52842, recall: 0.40686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 21:43:30,591] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-04 21:43:30,593] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "global step 410, epoch: 1, batch: 410, loss: 0.12904, auc: 0.83454, f1 score: 0.46708, speed: 0.04 step/s\n",
            "global step 420, epoch: 1, batch: 420, loss: 0.11919, auc: 0.84381, f1 score: 0.46768, speed: 0.13 step/s\n",
            "global step 430, epoch: 1, batch: 430, loss: 0.10399, auc: 0.84720, f1 score: 0.47409, speed: 0.14 step/s\n",
            "global step 440, epoch: 1, batch: 440, loss: 0.13203, auc: 0.84765, f1 score: 0.47075, speed: 0.14 step/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 21:51:29,774] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval loss: 0.12206, auc: 0.86582, f1 score: 0.46679, precison: 0.54320, recall: 0.40923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 21:51:30,487] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-04 21:51:30,489] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "global step 450, epoch: 1, batch: 450, loss: 0.11820, auc: 0.85680, f1 score: 0.45401, speed: 0.04 step/s\n",
            "global step 460, epoch: 1, batch: 460, loss: 0.09075, auc: 0.85544, f1 score: 0.45306, speed: 0.15 step/s\n",
            "global step 470, epoch: 1, batch: 470, loss: 0.11405, auc: 0.85278, f1 score: 0.44995, speed: 0.15 step/s\n",
            "global step 480, epoch: 1, batch: 480, loss: 0.11643, auc: 0.85486, f1 score: 0.45222, speed: 0.14 step/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 21:59:13,557] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval loss: 0.11775, auc: 0.87889, f1 score: 0.49405, precison: 0.52237, recall: 0.46864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 21:59:14,285] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-04 21:59:14,287] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "global step 490, epoch: 1, batch: 490, loss: 0.11837, auc: 0.87470, f1 score: 0.47417, speed: 0.04 step/s\n",
            "global step 500, epoch: 1, batch: 500, loss: 0.13096, auc: 0.87613, f1 score: 0.48684, speed: 0.16 step/s\n",
            "global step 510, epoch: 1, batch: 510, loss: 0.15116, auc: 0.87372, f1 score: 0.48902, speed: 0.15 step/s\n",
            "global step 520, epoch: 1, batch: 520, loss: 0.10809, auc: 0.87532, f1 score: 0.49209, speed: 0.13 step/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 22:06:43,514] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval loss: 0.11687, auc: 0.87709, f1 score: 0.49725, precison: 0.52600, recall: 0.47148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 22:06:44,229] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-04 22:06:44,231] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "global step 530, epoch: 1, batch: 530, loss: 0.11917, auc: 0.88291, f1 score: 0.50423, speed: 0.04 step/s\n",
            "global step 540, epoch: 1, batch: 540, loss: 0.12091, auc: 0.86679, f1 score: 0.48876, speed: 0.16 step/s\n",
            "global step 550, epoch: 1, batch: 550, loss: 0.10469, auc: 0.86861, f1 score: 0.49859, speed: 0.14 step/s\n",
            "global step 560, epoch: 1, batch: 560, loss: 0.12085, auc: 0.86756, f1 score: 0.49965, speed: 0.15 step/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 22:14:23,649] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval loss: 0.11427, auc: 0.88739, f1 score: 0.50437, precison: 0.53827, recall: 0.47448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 22:14:24,382] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-04 22:14:24,383] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "global step 570, epoch: 1, batch: 570, loss: 0.09709, auc: 0.89986, f1 score: 0.54307, speed: 0.04 step/s\n",
            "global step 580, epoch: 1, batch: 580, loss: 0.11051, auc: 0.87922, f1 score: 0.50454, speed: 0.16 step/s\n",
            "global step 590, epoch: 1, batch: 590, loss: 0.11759, auc: 0.88084, f1 score: 0.51282, speed: 0.15 step/s\n",
            "global step 600, epoch: 1, batch: 600, loss: 0.11930, auc: 0.88271, f1 score: 0.51291, speed: 0.13 step/s\n",
            "eval loss: 0.11333, auc: 0.89086, f1 score: 0.50147, precison: 0.50318, recall: 0.49976\n",
            "global step 610, epoch: 1, batch: 610, loss: 0.10866, auc: 0.89054, f1 score: 0.49340, speed: 0.04 step/s\n",
            "global step 620, epoch: 1, batch: 620, loss: 0.11903, auc: 0.88854, f1 score: 0.49838, speed: 0.15 step/s\n",
            "global step 630, epoch: 1, batch: 630, loss: 0.14733, auc: 0.88663, f1 score: 0.49107, speed: 0.16 step/s\n",
            "global step 640, epoch: 1, batch: 640, loss: 0.11789, auc: 0.89070, f1 score: 0.49106, speed: 0.15 step/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 22:29:45,783] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval loss: 0.11189, auc: 0.89704, f1 score: 0.51315, precison: 0.54588, recall: 0.48412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 22:29:46,509] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-04 22:29:46,511] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "global step 650, epoch: 1, batch: 650, loss: 0.10424, auc: 0.89951, f1 score: 0.51613, speed: 0.04 step/s\n",
            "global step 660, epoch: 1, batch: 660, loss: 0.10200, auc: 0.89790, f1 score: 0.49894, speed: 0.15 step/s\n",
            "global step 670, epoch: 1, batch: 670, loss: 0.10854, auc: 0.89744, f1 score: 0.49765, speed: 0.15 step/s\n",
            "global step 680, epoch: 1, batch: 680, loss: 0.10681, auc: 0.89464, f1 score: 0.50462, speed: 0.16 step/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 22:37:17,400] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval loss: 0.11030, auc: 0.89696, f1 score: 0.51802, precison: 0.54731, recall: 0.49170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 22:37:18,118] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-04 22:37:18,120] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "global step 690, epoch: 1, batch: 690, loss: 0.10154, auc: 0.89814, f1 score: 0.53739, speed: 0.04 step/s\n",
            "global step 700, epoch: 1, batch: 700, loss: 0.13622, auc: 0.88744, f1 score: 0.50988, speed: 0.15 step/s\n",
            "global step 710, epoch: 1, batch: 710, loss: 0.10032, auc: 0.89105, f1 score: 0.51221, speed: 0.15 step/s\n",
            "global step 720, epoch: 1, batch: 720, loss: 0.09950, auc: 0.88931, f1 score: 0.50793, speed: 0.15 step/s\n",
            "eval loss: 0.10918, auc: 0.90224, f1 score: 0.50898, precison: 0.50950, recall: 0.50845\n",
            "global step 730, epoch: 1, batch: 730, loss: 0.11668, auc: 0.89420, f1 score: 0.50197, speed: 0.04 step/s\n",
            "global step 740, epoch: 1, batch: 740, loss: 0.14501, auc: 0.89573, f1 score: 0.50289, speed: 0.16 step/s\n",
            "global step 750, epoch: 1, batch: 750, loss: 0.12266, auc: 0.89704, f1 score: 0.50290, speed: 0.15 step/s\n",
            "global step 760, epoch: 1, batch: 760, loss: 0.12493, auc: 0.89823, f1 score: 0.50758, speed: 0.16 step/s\n",
            "eval loss: 0.10850, auc: 0.90137, f1 score: 0.51577, precison: 0.54981, recall: 0.48570\n",
            "global step 770, epoch: 1, batch: 770, loss: 0.10721, auc: 0.89747, f1 score: 0.51053, speed: 0.04 step/s\n",
            "global step 780, epoch: 1, batch: 780, loss: 0.11399, auc: 0.89961, f1 score: 0.50236, speed: 0.17 step/s\n",
            "global step 790, epoch: 1, batch: 790, loss: 0.13156, auc: 0.90085, f1 score: 0.50224, speed: 0.15 step/s\n",
            "global step 800, epoch: 1, batch: 800, loss: 0.12935, auc: 0.90353, f1 score: 0.50517, speed: 0.14 step/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 22:59:54,135] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval loss: 0.10716, auc: 0.90740, f1 score: 0.52687, precison: 0.51445, recall: 0.53990\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 22:59:54,870] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-04 22:59:54,872] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "global step 810, epoch: 1, batch: 810, loss: 0.11516, auc: 0.89142, f1 score: 0.50503, speed: 0.04 step/s\n",
            "global step 820, epoch: 1, batch: 820, loss: 0.13035, auc: 0.90390, f1 score: 0.51800, speed: 0.15 step/s\n",
            "global step 830, epoch: 1, batch: 830, loss: 0.11803, auc: 0.90380, f1 score: 0.50831, speed: 0.14 step/s\n",
            "global step 840, epoch: 1, batch: 840, loss: 0.11679, auc: 0.90384, f1 score: 0.50450, speed: 0.14 step/s\n",
            "eval loss: 0.10702, auc: 0.90696, f1 score: 0.51223, precison: 0.54500, recall: 0.48317\n",
            "global step 850, epoch: 1, batch: 850, loss: 0.13263, auc: 0.90896, f1 score: 0.51102, speed: 0.04 step/s\n",
            "global step 860, epoch: 1, batch: 860, loss: 0.10852, auc: 0.90279, f1 score: 0.50972, speed: 0.13 step/s\n",
            "global step 870, epoch: 1, batch: 870, loss: 0.10953, auc: 0.90604, f1 score: 0.52067, speed: 0.13 step/s\n",
            "global step 880, epoch: 1, batch: 880, loss: 0.10212, auc: 0.90726, f1 score: 0.52153, speed: 0.12 step/s\n",
            "eval loss: 0.10608, auc: 0.91054, f1 score: 0.52578, precison: 0.55005, recall: 0.50356\n",
            "global step 890, epoch: 1, batch: 890, loss: 0.10225, auc: 0.91680, f1 score: 0.55007, speed: 0.04 step/s\n",
            "global step 900, epoch: 1, batch: 900, loss: 0.08211, auc: 0.91098, f1 score: 0.55117, speed: 0.14 step/s\n",
            "global step 910, epoch: 1, batch: 910, loss: 0.10483, auc: 0.91437, f1 score: 0.55005, speed: 0.13 step/s\n",
            "global step 920, epoch: 1, batch: 920, loss: 0.13403, auc: 0.91225, f1 score: 0.53324, speed: 0.13 step/s\n",
            "eval loss: 0.10696, auc: 0.91133, f1 score: 0.50972, precison: 0.48529, recall: 0.53674\n",
            "global step 930, epoch: 1, batch: 930, loss: 0.08086, auc: 0.92254, f1 score: 0.54478, speed: 0.04 step/s\n",
            "global step 940, epoch: 1, batch: 940, loss: 0.10627, auc: 0.91734, f1 score: 0.55527, speed: 0.14 step/s\n",
            "global step 950, epoch: 1, batch: 950, loss: 0.09819, auc: 0.91710, f1 score: 0.55172, speed: 0.15 step/s\n",
            "global step 960, epoch: 1, batch: 960, loss: 0.09143, auc: 0.91932, f1 score: 0.54802, speed: 0.15 step/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 23:31:58,822] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval loss: 0.10340, auc: 0.91560, f1 score: 0.53705, precison: 0.53880, recall: 0.53531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 23:31:59,538] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-04 23:31:59,540] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "global step 970, epoch: 1, batch: 970, loss: 0.12586, auc: 0.88200, f1 score: 0.47903, speed: 0.04 step/s\n",
            "global step 980, epoch: 1, batch: 980, loss: 0.13132, auc: 0.89910, f1 score: 0.51905, speed: 0.13 step/s\n",
            "global step 990, epoch: 1, batch: 990, loss: 0.09973, auc: 0.90215, f1 score: 0.51900, speed: 0.14 step/s\n",
            "global step 1000, epoch: 1, batch: 1000, loss: 0.10456, auc: 0.90564, f1 score: 0.51990, speed: 0.15 step/s\n",
            "eval loss: 0.10245, auc: 0.91878, f1 score: 0.53569, precison: 0.54139, recall: 0.53010\n",
            "global step 1010, epoch: 1, batch: 1010, loss: 0.08401, auc: 0.91287, f1 score: 0.55556, speed: 0.04 step/s\n",
            "global step 1020, epoch: 1, batch: 1020, loss: 0.09394, auc: 0.90927, f1 score: 0.52916, speed: 0.15 step/s\n",
            "global step 1030, epoch: 1, batch: 1030, loss: 0.08262, auc: 0.91460, f1 score: 0.52832, speed: 0.15 step/s\n",
            "global step 1040, epoch: 1, batch: 1040, loss: 0.11812, auc: 0.90952, f1 score: 0.52430, speed: 0.15 step/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 23:47:30,822] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval loss: 0.10107, auc: 0.92017, f1 score: 0.54827, precison: 0.55196, recall: 0.54464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-04 23:47:31,546] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-04 23:47:31,548] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "global step 1050, epoch: 1, batch: 1050, loss: 0.09609, auc: 0.90712, f1 score: 0.56327, speed: 0.04 step/s\n",
            "global step 1060, epoch: 1, batch: 1060, loss: 0.10066, auc: 0.91064, f1 score: 0.53633, speed: 0.16 step/s\n",
            "global step 1070, epoch: 1, batch: 1070, loss: 0.10138, auc: 0.91222, f1 score: 0.53126, speed: 0.16 step/s\n",
            "global step 1080, epoch: 1, batch: 1080, loss: 0.10533, auc: 0.91199, f1 score: 0.53112, speed: 0.15 step/s\n",
            "eval loss: 0.10142, auc: 0.92237, f1 score: 0.54153, precison: 0.53661, recall: 0.54653\n",
            "global step 1090, epoch: 1, batch: 1090, loss: 0.11467, auc: 0.91610, f1 score: 0.56704, speed: 0.04 step/s\n",
            "global step 1100, epoch: 1, batch: 1100, loss: 0.09732, auc: 0.91847, f1 score: 0.54244, speed: 0.14 step/s\n",
            "global step 1110, epoch: 1, batch: 1110, loss: 0.10782, auc: 0.92027, f1 score: 0.54004, speed: 0.15 step/s\n",
            "global step 1120, epoch: 1, batch: 1120, loss: 0.07969, auc: 0.91972, f1 score: 0.54070, speed: 0.15 step/s\n",
            "eval loss: 0.10140, auc: 0.91936, f1 score: 0.54462, precison: 0.55596, recall: 0.53373\n",
            "global step 1130, epoch: 1, batch: 1130, loss: 0.08509, auc: 0.91756, f1 score: 0.56226, speed: 0.04 step/s\n",
            "global step 1140, epoch: 1, batch: 1140, loss: 0.08385, auc: 0.92198, f1 score: 0.55985, speed: 0.14 step/s\n",
            "global step 1150, epoch: 1, batch: 1150, loss: 0.13188, auc: 0.91701, f1 score: 0.54692, speed: 0.13 step/s\n",
            "global step 1160, epoch: 1, batch: 1160, loss: 0.13752, auc: 0.91153, f1 score: 0.54134, speed: 0.14 step/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-05 00:10:33,188] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval loss: 0.09988, auc: 0.92286, f1 score: 0.55216, precison: 0.59001, recall: 0.51888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-05 00:10:33,899] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-05 00:10:33,902] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "global step 1170, epoch: 1, batch: 1170, loss: 0.08678, auc: 0.92070, f1 score: 0.55156, speed: 0.04 step/s\n",
            "global step 1180, epoch: 1, batch: 1180, loss: 0.11239, auc: 0.91911, f1 score: 0.54484, speed: 0.14 step/s\n",
            "global step 1190, epoch: 1, batch: 1190, loss: 0.11564, auc: 0.91969, f1 score: 0.54626, speed: 0.15 step/s\n",
            "global step 1200, epoch: 1, batch: 1200, loss: 0.09124, auc: 0.92337, f1 score: 0.54933, speed: 0.14 step/s\n",
            "eval loss: 0.09974, auc: 0.92641, f1 score: 0.54567, precison: 0.55059, recall: 0.54084\n",
            "global step 1210, epoch: 1, batch: 1210, loss: 0.10039, auc: 0.92296, f1 score: 0.56991, speed: 0.04 step/s\n",
            "global step 1220, epoch: 1, batch: 1220, loss: 0.11269, auc: 0.92089, f1 score: 0.57087, speed: 0.15 step/s\n",
            "global step 1230, epoch: 1, batch: 1230, loss: 0.09229, auc: 0.92414, f1 score: 0.56665, speed: 0.15 step/s\n",
            "global step 1240, epoch: 1, batch: 1240, loss: 0.09707, auc: 0.92181, f1 score: 0.55995, speed: 0.15 step/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-05 00:26:00,355] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval loss: 0.09880, auc: 0.92551, f1 score: 0.55532, precison: 0.55353, recall: 0.55712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-05 00:26:01,066] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-05 00:26:01,068] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "global step 1250, epoch: 1, batch: 1250, loss: 0.09870, auc: 0.92815, f1 score: 0.52854, speed: 0.04 step/s\n",
            "global step 1260, epoch: 1, batch: 1260, loss: 0.09591, auc: 0.92453, f1 score: 0.53652, speed: 0.17 step/s\n",
            "global step 1270, epoch: 1, batch: 1270, loss: 0.09316, auc: 0.92451, f1 score: 0.54033, speed: 0.15 step/s\n",
            "global step 1280, epoch: 1, batch: 1280, loss: 0.10688, auc: 0.92514, f1 score: 0.55295, speed: 0.15 step/s\n",
            "eval loss: 0.10133, auc: 0.91816, f1 score: 0.54930, precison: 0.55702, recall: 0.54179\n",
            "global step 1290, epoch: 1, batch: 1290, loss: 0.10055, auc: 0.91673, f1 score: 0.55633, speed: 0.04 step/s\n",
            "global step 1300, epoch: 1, batch: 1300, loss: 0.08017, auc: 0.92148, f1 score: 0.55065, speed: 0.16 step/s\n",
            "global step 1310, epoch: 1, batch: 1310, loss: 0.07121, auc: 0.92086, f1 score: 0.54866, speed: 0.15 step/s\n",
            "global step 1320, epoch: 1, batch: 1320, loss: 0.08120, auc: 0.92289, f1 score: 0.55025, speed: 0.15 step/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-05 00:40:59,080] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval loss: 0.09750, auc: 0.93042, f1 score: 0.55913, precison: 0.56872, recall: 0.54985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-05 00:40:59,806] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-05 00:40:59,808] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "global step 1330, epoch: 1, batch: 1330, loss: 0.10641, auc: 0.91736, f1 score: 0.52516, speed: 0.04 step/s\n",
            "global step 1340, epoch: 1, batch: 1340, loss: 0.12978, auc: 0.92387, f1 score: 0.55385, speed: 0.14 step/s\n",
            "global step 1350, epoch: 1, batch: 1350, loss: 0.10373, auc: 0.92680, f1 score: 0.56456, speed: 0.15 step/s\n",
            "global step 1360, epoch: 1, batch: 1360, loss: 0.12953, auc: 0.92118, f1 score: 0.55718, speed: 0.15 step/s\n",
            "eval loss: 0.09847, auc: 0.92812, f1 score: 0.55195, precison: 0.54627, recall: 0.55775\n",
            "global step 1370, epoch: 1, batch: 1370, loss: 0.13794, auc: 0.91325, f1 score: 0.55065, speed: 0.04 step/s\n",
            "global step 1380, epoch: 1, batch: 1380, loss: 0.10697, auc: 0.91639, f1 score: 0.54065, speed: 0.16 step/s\n",
            "global step 1390, epoch: 1, batch: 1390, loss: 0.10250, auc: 0.91938, f1 score: 0.54889, speed: 0.14 step/s\n",
            "global step 1400, epoch: 1, batch: 1400, loss: 0.09740, auc: 0.92361, f1 score: 0.54951, speed: 0.15 step/s\n",
            "eval loss: 0.09798, auc: 0.92837, f1 score: 0.55397, precison: 0.53805, recall: 0.57086\n",
            "global step 1410, epoch: 1, batch: 1410, loss: 0.09707, auc: 0.92632, f1 score: 0.52703, speed: 0.04 step/s\n",
            "global step 1420, epoch: 1, batch: 1420, loss: 0.09919, auc: 0.92564, f1 score: 0.51971, speed: 0.16 step/s\n",
            "global step 1430, epoch: 1, batch: 1430, loss: 0.09028, auc: 0.92698, f1 score: 0.53535, speed: 0.16 step/s\n",
            "global step 1440, epoch: 1, batch: 1440, loss: 0.10686, auc: 0.92543, f1 score: 0.53823, speed: 0.15 step/s\n",
            "eval loss: 0.09842, auc: 0.93068, f1 score: 0.55101, precison: 0.54131, recall: 0.56107\n",
            "global step 1450, epoch: 1, batch: 1450, loss: 0.08547, auc: 0.91497, f1 score: 0.50948, speed: 0.04 step/s\n",
            "global step 1460, epoch: 1, batch: 1460, loss: 0.09868, auc: 0.92278, f1 score: 0.53560, speed: 0.15 step/s\n",
            "global step 1470, epoch: 1, batch: 1470, loss: 0.08792, auc: 0.92410, f1 score: 0.53985, speed: 0.16 step/s\n",
            "global step 1480, epoch: 1, batch: 1480, loss: 0.07759, auc: 0.92663, f1 score: 0.54810, speed: 0.15 step/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-05 01:11:21,355] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval loss: 0.09693, auc: 0.93068, f1 score: 0.56047, precison: 0.53784, recall: 0.58508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-05 01:11:22,062] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-05 01:11:22,064] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "global step 1490, epoch: 1, batch: 1490, loss: 0.13433, auc: 0.92254, f1 score: 0.55367, speed: 0.04 step/s\n",
            "global step 1500, epoch: 1, batch: 1500, loss: 0.10612, auc: 0.92479, f1 score: 0.56496, speed: 0.15 step/s\n",
            "global step 1510, epoch: 1, batch: 1510, loss: 0.09777, auc: 0.92633, f1 score: 0.56106, speed: 0.15 step/s\n",
            "global step 1520, epoch: 1, batch: 1520, loss: 0.11920, auc: 0.92645, f1 score: 0.55273, speed: 0.14 step/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-05 01:19:01,212] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt/config.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval loss: 0.09662, auc: 0.92884, f1 score: 0.56616, precison: 0.55569, recall: 0.57703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2023-04-05 01:19:01,911] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt/tokenizer_config.json\u001b[0m\n",
            "\u001b[32m[2023-04-05 01:19:01,913] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt/special_tokens_map.json\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "epochs = 1 # training times\n",
        "ckpt_dir = \"ernie_ckpt\" # Folder for saving model parameters during training\n",
        "\n",
        "global_step = 0  # Number of iterations\n",
        "tic_train = time.time()\n",
        "best_f1_score = 0\n",
        "\n",
        "# Model Training\n",
        "for epoch in range(1, epochs + 1):\n",
        "    for step, batch in enumerate(train_data_loader, start=1):\n",
        "        input_ids, token_type_ids, labels = batch['input_ids'], batch['token_type_ids'], batch['labels']\n",
        "\n",
        "        # Calculate model output, loss function value, classification probability value, accuracy, f1 score.\n",
        "        logits = model(input_ids, token_type_ids)\n",
        "        loss = criterion(logits, labels)\n",
        "        probs = F.sigmoid(logits)\n",
        "        metric.update(probs, labels)\n",
        "        auc, f1_score, _, _ = metric.accumulate()\n",
        "\n",
        "        # Print the loss function value, accuracy, f1 score, and computation speed for each 10 iterations.\n",
        "        global_step += 1\n",
        "        if global_step % 10 == 0:\n",
        "            print(\n",
        "                \"global step %d, epoch: %d, batch: %d, loss: %.5f, auc: %.5f, f1 score: %.5f, speed: %.2f step/s\"\n",
        "                % (global_step, epoch, step, loss, auc, f1_score,\n",
        "                    10 / (time.time() - tic_train)))\n",
        "            tic_train = time.time()\n",
        "        \n",
        "        # Reverse gradient passback with updated parameters.\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.clear_grad()\n",
        "        \n",
        "        # Every 40 iterations, evaluate the current trained model, save the current best model parameters and word list of the word splitter, etc.\n",
        "        if global_step % 40 == 0:\n",
        "            save_dir = ckpt_dir\n",
        "            if not os.path.exists(save_dir):\n",
        "                os.makedirs(save_dir)\n",
        "            eval_f1_score = evaluate(model, criterion, metric, test_data_loader, label_vocab, if_return_results=False)\n",
        "            if eval_f1_score > best_f1_score:\n",
        "                best_f1_score = eval_f1_score\n",
        "                model.save_pretrained(save_dir)\n",
        "                tokenizer.save_pretrained(save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLbem2Gk6270",
        "outputId": "5415856c-c1b0-40b9-ac71-58cf781739b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERNIE 3.0 performance on GoEmotions micro-emotion 28 classification test set： eval loss: 0.09662, auc: 0.92884, f1 score: 0.56616, precison: 0.55569, recall: 0.57703\n"
          ]
        }
      ],
      "source": [
        "# Load the optimal parameters of the trained model.\n",
        "model.set_dict(paddle.load('ernie_ckpt/model_state.pdparams'))\n",
        "\n",
        "# Load the parameters of the previously trained model.\n",
        "# model.set_dict(paddle.load('/home/aistudio/work/model_state.pdparams'))\n",
        "\n",
        "# Model Validation.\n",
        "print(\"ERNIE 3.0 performance on GoEmotions micro-emotion 28 classification test set：\", end= \" \")\n",
        "results = evaluate(model, criterion, metric, test_data_loader, label_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KlKCxQYjPS3C"
      },
      "outputs": [],
      "source": [
        "# 定义数据加载和处理函数\n",
        "from paddlenlp.data import JiebaTokenizer, Pad, Stack, Tuple, Vocab\n",
        "def convert_example(example, tokenizer, max_seq_length=64, is_test=False):\n",
        "    qtconcat = example[\"text\"]\n",
        "    encoded_inputs = tokenizer(text=qtconcat, max_seq_len=max_seq_length)\n",
        "    input_ids = encoded_inputs[\"input_ids\"]\n",
        "    token_type_ids = encoded_inputs[\"token_type_ids\"]\n",
        "    if not is_test:\n",
        "        label = np.array([example[\"label\"]], dtype=\"int64\")\n",
        "        return input_ids, token_type_ids, label\n",
        "    else:\n",
        "        return input_ids, token_type_ids\n",
        "\n",
        "# 定义模型预测函数\n",
        "def predict(model, data, tokenizer, label_vocab, batch_size=1, max_seq=64):\n",
        "    examples = []\n",
        "    # 将输入数据（list格式）处理为模型可接受的格式\n",
        "    for text in data:\n",
        "        input_ids, segment_ids = convert_example(\n",
        "            text,\n",
        "            tokenizer,\n",
        "            max_seq_length=max_seq,\n",
        "            is_test=True)\n",
        "        examples.append((input_ids, segment_ids))\n",
        "\n",
        "    batchify_fn = lambda samples, fn=Tuple(\n",
        "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input id\n",
        "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # segment id\n",
        "    ): fn(samples)\n",
        "\n",
        "    # Seperates data into some batches.\n",
        "    batches = []\n",
        "    one_batch = []\n",
        "    for example in examples:\n",
        "        one_batch.append(example)\n",
        "        if len(one_batch) == batch_size:\n",
        "            batches.append(one_batch)\n",
        "            one_batch = []\n",
        "    if one_batch:\n",
        "        # The last batch whose size is less than the config batch_size setting.\n",
        "        batches.append(one_batch)\n",
        "\n",
        "    results = []\n",
        "    model.eval()\n",
        "    for batch in batches:\n",
        "        input_ids, segment_ids = batchify_fn(batch)\n",
        "        input_ids = paddle.to_tensor(input_ids)\n",
        "        segment_ids = paddle.to_tensor(segment_ids)\n",
        "        logits = model(input_ids, segment_ids)\n",
        "        probs = F.sigmoid(logits)\n",
        "        probs = probs.tolist()\n",
        "        # 结果处理,选取概率大于0.5的情感类别\n",
        "        for prob in probs:\n",
        "            result = []\n",
        "            for c, pred in enumerate(prob):\n",
        "                if pred > 0.5:\n",
        "                    result.append(label_vocab[c])\n",
        "            results.append(','.join(result))\n",
        "    return results  # 返回预测结果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "3W2OfqsBRfB1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02108fee-776c-4de9-c907-9a077c33e4b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: Thats absolutely disgusting. \t Lables: \n",
            "Text: Why would I do that? \t Lables: curiosity\n",
            "Text: You shut your mouth \t Lables: anger\n",
            "Text: Thank you. \t Lables: gratitude\n"
          ]
        }
      ],
      "source": [
        "# 定义要进行微情感分析的文本数据\n",
        "data = [\n",
        "    # 11 disgust\n",
        "    {\"text\": 'Thats absolutely disgusting.'},\n",
        "    # 7 curiosity\n",
        "    {\"text\":'Why would I do that?'},\n",
        "    # 2 anger\n",
        "    {\"text\":\"You shut your mouth\"},\n",
        "    # 15 gratitude\n",
        "    {\"text\":\"Thank you.\"}\n",
        "]\n",
        "\n",
        "# 模型预测\n",
        "labels =  predict(model, data, tokenizer, label_vocab, batch_size=1)\n",
        "\n",
        "# 输出预测结果\n",
        "for idx, text in enumerate(data):\n",
        "    print('Text: {} \\t Lables: {}'.format(text['text'], labels[idx]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9DDfiSCsA2ur"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8f0bb537306940a192c374f5458f3c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d6f5d91a6c34eb2be6c43b9d77316c2",
              "IPY_MODEL_5a0a3265f4fc40acac71a85fc3a29c97",
              "IPY_MODEL_5f302f73d14d4aa68d48a8d06c4d8717"
            ],
            "layout": "IPY_MODEL_3f2a18e109734e53bd330eceb3d79712"
          }
        },
        "9d6f5d91a6c34eb2be6c43b9d77316c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0b878e93f3b4a2a9b3de57d15ab55e1",
            "placeholder": "​",
            "style": "IPY_MODEL_6d0f814a0b03493abe1044ef14bf15dc",
            "value": "100%"
          }
        },
        "5a0a3265f4fc40acac71a85fc3a29c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23288bf360984ed182be7d6d84841716",
            "max": 327709220,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce8f3f6b29f74c94aedc579412a4aa5e",
            "value": 327709220
          }
        },
        "5f302f73d14d4aa68d48a8d06c4d8717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5269406c713340ceb8f6bd40782769d7",
            "placeholder": "​",
            "style": "IPY_MODEL_74a0ab1a08ee49cba9f797176a92b2f2",
            "value": " 313M/313M [00:19&lt;00:00, 30.8MB/s]"
          }
        },
        "3f2a18e109734e53bd330eceb3d79712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0b878e93f3b4a2a9b3de57d15ab55e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d0f814a0b03493abe1044ef14bf15dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23288bf360984ed182be7d6d84841716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce8f3f6b29f74c94aedc579412a4aa5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5269406c713340ceb8f6bd40782769d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74a0ab1a08ee49cba9f797176a92b2f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bcd679979a14b92ad7bd28b58ed883f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac8d5f80a0324c538908ab32974f9b6a",
              "IPY_MODEL_751c62037368473dac02b36dd1c0b05f",
              "IPY_MODEL_6e257f83475345ddbed64f81dccfb309"
            ],
            "layout": "IPY_MODEL_290bc213ab9e48898ebbc8c4e31fe36e"
          }
        },
        "ac8d5f80a0324c538908ab32974f9b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94803e83cafa4a50bb2d8a3fbaf73274",
            "placeholder": "​",
            "style": "IPY_MODEL_faa019ca3caa4a4e809a1612319ac503",
            "value": "100%"
          }
        },
        "751c62037368473dac02b36dd1c0b05f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36f1a68b633d45c08eb1fc80d282838d",
            "max": 186807,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62335350a40e41d1b1fe80e221baa984",
            "value": 186807
          }
        },
        "6e257f83475345ddbed64f81dccfb309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef7240d1bccd40ebbd05455bb4c994bf",
            "placeholder": "​",
            "style": "IPY_MODEL_d79c404107ff4d16a3945df9b74ec5d3",
            "value": " 182k/182k [00:00&lt;00:00, 490kB/s]"
          }
        },
        "290bc213ab9e48898ebbc8c4e31fe36e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94803e83cafa4a50bb2d8a3fbaf73274": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faa019ca3caa4a4e809a1612319ac503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36f1a68b633d45c08eb1fc80d282838d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62335350a40e41d1b1fe80e221baa984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef7240d1bccd40ebbd05455bb4c994bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d79c404107ff4d16a3945df9b74ec5d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}