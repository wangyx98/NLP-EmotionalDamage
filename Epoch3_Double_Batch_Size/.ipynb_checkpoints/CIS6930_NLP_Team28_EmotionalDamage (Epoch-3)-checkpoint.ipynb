{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORgmwobm4_g2"
   },
   "source": [
    "# Load dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrMTeAyDlOBQ"
   },
   "source": [
    "## Go to the dataset directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64uskL5n_Vzk",
    "outputId": "36e9e97e-de23-4b52-f7b8-0fd46b9361fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] 系统找不到指定的文件。: 'dataset/'\n",
      "C:\\Users\\hjh\\Documents\\UFL\\23 Spring\\CIS6930-NLP\\Project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "%cd dataset/\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSYmlicmmRKy"
   },
   "source": [
    "## Import the pandas library and perform data reading for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UZm7nLTKmfdz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('train.csv', sep='\\t', header=None)\n",
    "test = pd.read_csv('test.csv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIn3DaU_mm7s"
   },
   "source": [
    "## Adding column names to data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oUnLTl9Nmxd1"
   },
   "outputs": [],
   "source": [
    "train.columns = [\"text\",'labels']\n",
    "test.columns = [\"text\",'labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWslftXjm08j"
   },
   "source": [
    "## The first 10 texts of the training set are read in the format \"text, labels\". The labels may contain multiple sentiment categories, each sentiment is separated by ','."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "eZwM1noTnqph",
    "outputId": "9f63e31e-67f2-47f2-ab85-906053e9c0df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yes I heard abt the f bombs! That has to be wh...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We need more boards and to create a bit more s...</td>\n",
       "      <td>8,20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Damn youtube and outrage drama is super lucrat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>It might be linked to the trust factor of your...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text labels\n",
       "0  My favourite food is anything I didn't have to...     27\n",
       "1  Now if he does off himself, everyone will thin...     27\n",
       "2                     WHY THE FUCK IS BAYLESS ISOING      2\n",
       "3                        To make her feel threatened     14\n",
       "4                             Dirty Southern Wankers      3\n",
       "5  OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe...     26\n",
       "6  Yes I heard abt the f bombs! That has to be wh...     15\n",
       "7  We need more boards and to create a bit more s...   8,20\n",
       "8  Damn youtube and outrage drama is super lucrat...      0\n",
       "9  It might be linked to the trust factor of your...     27"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "foY1dbLhn3nG",
    "outputId": "aded24be-5d4e-4e5f-9485-34d655a6c09a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I’m really sorry about your situation :( Altho...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's wonderful because it's awful. At not with.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kings fan here, good luck to you guys! Will be...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I didn't know that, thank you for teaching me ...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They got bored from haunting earth for thousan...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thank you for asking questions and recognizing...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>You’re welcome</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100%! Congrats on your job too!</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I’m sorry to hear that friend :(. It’s for the...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Girlfriend weak as well, that jump was pathetic.</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text labels\n",
       "0  I’m really sorry about your situation :( Altho...     25\n",
       "1    It's wonderful because it's awful. At not with.      0\n",
       "2  Kings fan here, good luck to you guys! Will be...     13\n",
       "3  I didn't know that, thank you for teaching me ...     15\n",
       "4  They got bored from haunting earth for thousan...     27\n",
       "5  Thank you for asking questions and recognizing...     15\n",
       "6                                     You’re welcome     15\n",
       "7                    100%! Congrats on your job too!     15\n",
       "8  I’m sorry to hear that friend :(. It’s for the...     24\n",
       "9   Girlfriend weak as well, that jump was pathetic.     25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHfWI95Tq3d7"
   },
   "source": [
    "# Install and import related libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OWpIE-2jq8f-",
    "outputId": "086d358e-0c80-4cb4-8283-2862ed86ae85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: paddlenlp in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (2.5.2)\n",
      "Requirement already satisfied: uvicorn in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from paddlenlp) (0.21.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from paddlenlp) (6.7.0)\n",
      "Requirement already satisfied: multiprocess<=0.70.12.2 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from paddlenlp) (0.70.12.2)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from paddlenlp) (0.1.98)\n",
      "Requirement already satisfied: seqeval in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from paddlenlp) (1.2.2)\n",
      "Requirement already satisfied: Flask-Babel<3.0.0 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from paddlenlp) (2.0.0)\n",
      "Requirement already satisfied: rich in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from paddlenlp) (13.3.4)\n",
      "Requirement already satisfied: visualdl in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from paddlenlp) (2.4.2)\n",
      "Requirement already satisfied: typer in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from paddlenlp) (0.7.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from paddlenlp) (2.11.0)\n",
      "Requirement already satisfied: colorama in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from paddlenlp) (0.4.4)\n",
      "Requirement already satisfied: paddlefsl in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from paddlenlp) (1.1.0)\n",
      "Requirement already satisfied: fastapi in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from paddlenlp) (0.95.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.11.1 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from paddlenlp) (0.13.4)\n",
      "Requirement already satisfied: dill<0.3.5 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from paddlenlp) (0.3.4)\n",
      "Requirement already satisfied: jieba in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied: paddle2onnx in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from paddlenlp) (1.0.6)\n",
      "Requirement already satisfied: tqdm in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from paddlenlp) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from datasets>=2.0.0->paddlenlp) (3.8.4)\n",
      "Requirement already satisfied: packaging in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from datasets>=2.0.0->paddlenlp) (21.3)\n",
      "Requirement already satisfied: pandas in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from datasets>=2.0.0->paddlenlp) (1.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from datasets>=2.0.0->paddlenlp) (1.22.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from datasets>=2.0.0->paddlenlp) (2023.4.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from datasets>=2.0.0->paddlenlp) (2.27.1)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from datasets>=2.0.0->paddlenlp) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from datasets>=2.0.0->paddlenlp) (11.0.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from datasets>=2.0.0->paddlenlp) (3.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from datasets>=2.0.0->paddlenlp) (6.0)\n",
      "Requirement already satisfied: Babel>=2.3 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from Flask-Babel<3.0.0->paddlenlp) (2.12.1)\n",
      "Requirement already satisfied: Jinja2>=2.5 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from Flask-Babel<3.0.0->paddlenlp) (3.0.3)\n",
      "Requirement already satisfied: Flask in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from Flask-Babel<3.0.0->paddlenlp) (2.2.3)\n",
      "Requirement already satisfied: pytz in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from Flask-Babel<3.0.0->paddlenlp) (2021.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (2.0.10)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.9.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.11.1->paddlenlp) (4.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.11.1->paddlenlp) (3.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from Jinja2>=2.5->Flask-Babel<3.0.0->paddlenlp) (2.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from packaging->datasets>=2.0.0->paddlenlp) (3.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (1.26.8)\n",
      "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from fastapi->paddlenlp) (1.10.7)\n",
      "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from fastapi->paddlenlp) (0.26.1)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from starlette<0.27.0,>=0.26.1->fastapi->paddlenlp) (3.6.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi->paddlenlp) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from Flask->Flask-Babel<3.0.0->paddlenlp) (8.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from Flask->Flask-Babel<3.0.0->paddlenlp) (4.10.1)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from Flask->Flask-Babel<3.0.0->paddlenlp) (2.2.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from Flask->Flask-Babel<3.0.0->paddlenlp) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from importlib-metadata>=3.6.0->Flask->Flask-Babel<3.0.0->paddlenlp) (3.7.0)\n",
      "Requirement already satisfied: six in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from paddle2onnx->paddlenlp) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from pandas->datasets>=2.0.0->paddlenlp) (2.8.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from rich->paddlenlp) (2.15.1)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from rich->paddlenlp) (2.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->paddlenlp) (0.1.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from seqeval->paddlenlp) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from uvicorn->paddlenlp) (0.14.0)\n",
      "Requirement already satisfied: matplotlib in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from visualdl->paddlenlp) (3.5.1)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from visualdl->paddlenlp) (9.0.0)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from visualdl->paddlenlp) (3.19.3)\n",
      "Requirement already satisfied: bce-python-sdk in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from visualdl->paddlenlp) (0.8.83)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.17)\n",
      "Requirement already satisfied: future>=0.6.0 in c:\\users\\hjh\\appdata\\roaming\\python\\python39\\site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.3)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from matplotlib->visualdl->paddlenlp) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from matplotlib->visualdl->paddlenlp) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from matplotlib->visualdl->paddlenlp) (4.28.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "herF3Q2qrfVf",
    "outputId": "ff5701b0-f4ec-49fa-fb34-6fbc0c05da1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: paddlepaddle in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (2.4.2)\n",
      "Requirement already satisfied: opt-einsum==3.3.0 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from paddlepaddle) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.13 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from paddlepaddle) (1.22.1)\n",
      "Requirement already satisfied: astor in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from paddlepaddle) (0.8.1)\n",
      "Requirement already satisfied: protobuf<=3.20.0,>=3.1.0 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from paddlepaddle) (3.19.3)\n",
      "Requirement already satisfied: requests>=2.20.0 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from paddlepaddle) (2.27.1)\n",
      "Requirement already satisfied: decorator in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from paddlepaddle) (5.1.1)\n",
      "Requirement already satisfied: six in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from paddlepaddle) (1.16.0)\n",
      "Requirement already satisfied: Pillow in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from paddlepaddle) (9.0.0)\n",
      "Requirement already satisfied: paddle-bfloat==0.1.7 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from paddlepaddle) (0.1.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from requests>=2.20.0->paddlepaddle) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from requests>=2.20.0->paddlepaddle) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from requests>=2.20.0->paddlepaddle) (2.0.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\miniconda3\\envs\\amlc\\lib\\site-packages (from requests>=2.20.0->paddlepaddle) (1.26.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install paddlepaddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "X7YvSrZprIz3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import paddle\n",
    "import paddlenlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fafm1FtVsfGY"
   },
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0jIHcPbsiIz"
   },
   "source": [
    "## For the 28 micro-sentiment multi-label classification scenario, where a sentence may correspond to multiple sentiment category labels, the sentiment labels of the dataset need to be transformed using One-Hot coding first, with \"0\" indicating absence and \"1\" indicating presence for each sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTPiTK0pstvz"
   },
   "source": [
    "### Create sentiment label mapping relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XQmitCV3tNrx"
   },
   "outputs": [],
   "source": [
    "label_vocab = {\n",
    "    0: \"admiration\",\n",
    "    1: \"amusement\",\n",
    "    2: \"anger\",\n",
    "    3: \"annoyance\",\n",
    "    4: \"approval\",\n",
    "    5: \"caring\",\n",
    "    6: \"confusion\",\n",
    "    7: \"curiosity\",\n",
    "    8: \"desire\",\n",
    "    9: \"disappointment\",\n",
    "    10: \"disapproval\",\n",
    "    11: \"disgust\",\n",
    "    12: \"embarrassment\",\n",
    "    13: \"excitement\",\n",
    "    14: \"fear\",\n",
    "    15: \"gratitude\",\n",
    "    16: \"grief\",\n",
    "    17: \"joy\",\n",
    "    18: \"love\",\n",
    "    19: \"nervousness\",\n",
    "    20: \"optimism\",\n",
    "    21: \"pride\",\n",
    "    22: \"realization\",\n",
    "    23: \"relief\",\n",
    "    24: \"remorse\",\n",
    "    25: \"sadness\",\n",
    "    26: \"surprise\",\n",
    "    27: \"neutral\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-EcFAvotT5Q"
   },
   "source": [
    "### Customize the dataset, read the data file, create the dataset and define the data type as MapDataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "FhHKTcR7t3Xq"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from paddlenlp.datasets import load_dataset\n",
    "\n",
    "# Clear invalid characters\n",
    "def clean_text(text):\n",
    "    text = text.replace(\"\\r\", \"\").replace(\"\\n\", \"\")\n",
    "    text = re.sub(r\"\\\\n\\n\", \".\", text)\n",
    "    return text\n",
    "\n",
    "# Define the read data set function\n",
    "def read_custom_data(filepath, is_one_hot=True):\n",
    "    f = open(filepath)\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        data = line.strip().split('\\t')\n",
    "        # One-hot processing for 28 types of micro sentiment tags\n",
    "        if is_one_hot:\n",
    "            labels = [float(1) if str(i) in data[1].split(',') else float(0) for i in range(28)]  # 28 types\n",
    "        else:\n",
    "            labels = [int(d) for d in data[1].split(',')]\n",
    "        yield {\"text\": clean_text(data[0]), \"labels\": labels}\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "M_SQ3JwruQSe"
   },
   "outputs": [],
   "source": [
    "# load_dataset() to Create dataset.\n",
    "# lazy=False，The dataset is returned as a MapDataset type.\n",
    "# Pre-processing of training and validation sets.\n",
    "train_ds = load_dataset(read_custom_data, filepath='train.csv', lazy=False) \n",
    "test_ds = load_dataset(read_custom_data, filepath='test.csv', lazy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9nrlxqJwCQq"
   },
   "source": [
    "### Print dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bExeME40wGuv",
    "outputId": "b8ebe161-e02a-4306-e60f-df00b2b99b44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datatype: <class 'paddlenlp.datasets.dataset.MapDataset'>\n",
      "training dataset example: {'text': \"My favourite food is anything I didn't have to cook myself.\", 'labels': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}\n",
      "testing dataset example: {'text': 'I’m really sorry about your situation :( Although I love the names Sapphira, Cirilla, and Scarlett!', 'labels': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}\n"
     ]
    }
   ],
   "source": [
    "print(\"datatype:\", type(train_ds))\n",
    "print(\"training dataset example:\", train_ds[0])\n",
    "print(\"testing dataset example:\", test_ds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEqnn-WG4Pa2"
   },
   "source": [
    "## Load Chinese ERNIE 3.0 pre-training model and word splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8f0bb537306940a192c374f5458f3c99",
      "9d6f5d91a6c34eb2be6c43b9d77316c2",
      "5a0a3265f4fc40acac71a85fc3a29c97",
      "5f302f73d14d4aa68d48a8d06c4d8717",
      "3f2a18e109734e53bd330eceb3d79712",
      "d0b878e93f3b4a2a9b3de57d15ab55e1",
      "6d0f814a0b03493abe1044ef14bf15dc",
      "23288bf360984ed182be7d6d84841716",
      "ce8f3f6b29f74c94aedc579412a4aa5e",
      "5269406c713340ceb8f6bd40782769d7",
      "74a0ab1a08ee49cba9f797176a92b2f2",
      "6bcd679979a14b92ad7bd28b58ed883f",
      "ac8d5f80a0324c538908ab32974f9b6a",
      "751c62037368473dac02b36dd1c0b05f",
      "6e257f83475345ddbed64f81dccfb309",
      "290bc213ab9e48898ebbc8c4e31fe36e",
      "94803e83cafa4a50bb2d8a3fbaf73274",
      "faa019ca3caa4a4e809a1612319ac503",
      "36f1a68b633d45c08eb1fc80d282838d",
      "62335350a40e41d1b1fe80e221baa984",
      "ef7240d1bccd40ebbd05455bb4c994bf",
      "d79c404107ff4d16a3945df9b74ec5d3"
     ]
    },
    "id": "4dJq6b6D4L-w",
    "outputId": "f5de5d1e-4388-4282-dbf6-c671a9320125"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-22 22:24:39,096] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.ernie.modeling.ErnieForSequenceClassification'> to load 'ernie-3.0-medium-zh'.\u001b[0m\n",
      "\u001b[32m[2023-04-22 22:24:39,098] [    INFO]\u001b[0m - Model config ErnieConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"enable_recompute\": false,\n",
      "  \"fuse\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"ernie\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"paddlenlp_version\": null,\n",
      "  \"pool_act\": \"tanh\",\n",
      "  \"task_id\": 0,\n",
      "  \"task_type_vocab_size\": 16,\n",
      "  \"type_vocab_size\": 4,\n",
      "  \"use_task_id\": true,\n",
      "  \"vocab_size\": 40000\n",
      "}\n",
      "\u001b[0m\n",
      "\u001b[32m[2023-04-22 22:24:39,100] [    INFO]\u001b[0m - Configuration saved in C:\\Users\\hjh\\.paddlenlp\\models\\ernie-3.0-medium-zh\\config.json\u001b[0m\n",
      "\u001b[32m[2023-04-22 22:24:39,103] [    INFO]\u001b[0m - Downloading ernie_3.0_medium_zh.pdparams from https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_medium_zh.pdparams\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec53c92891aa4d6eba39220da5d832e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/313M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2023-04-22 22:27:00,698] [ WARNING]\u001b[0m - Some weights of the model checkpoint at ernie-3.0-medium-zh were not used when initializing ErnieForSequenceClassification: ['ernie.encoder.layers.6.norm2.weight', 'ernie.encoder.layers.6.self_attn.q_proj.bias', 'ernie.encoder.layers.6.self_attn.k_proj.weight', 'ernie.encoder.layers.6.self_attn.k_proj.bias', 'ernie.encoder.layers.6.self_attn.v_proj.bias', 'ernie.encoder.layers.6.self_attn.q_proj.weight', 'ernie.encoder.layers.6.norm2.bias', 'ernie.encoder.layers.6.self_attn.out_proj.bias', 'ernie.encoder.layers.6.linear1.weight', 'ernie.encoder.layers.6.norm1.weight', 'ernie.encoder.layers.6.linear2.weight', 'ernie.encoder.layers.6.linear2.bias', 'ernie.encoder.layers.6.norm1.bias', 'ernie.encoder.layers.6.linear1.bias', 'ernie.encoder.layers.6.self_attn.v_proj.weight', 'ernie.encoder.layers.6.self_attn.out_proj.weight']\n",
      "- This IS expected if you are initializing ErnieForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ErnieForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[33m[2023-04-22 22:27:00,699] [ WARNING]\u001b[0m - Some weights of ErnieForSequenceClassification were not initialized from the model checkpoint at ernie-3.0-medium-zh and are newly initialized: ['classifier.bias', 'classifier.weight', 'ernie.pooler.dense.weight', 'ernie.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[32m[2023-04-22 22:27:00,700] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load 'ernie-3.0-medium-zh'.\u001b[0m\n",
      "\u001b[32m[2023-04-22 22:27:00,701] [    INFO]\u001b[0m - Downloading https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_medium_zh_vocab.txt and saved to C:\\Users\\hjh\\.paddlenlp\\models\\ernie-3.0-medium-zh\u001b[0m\n",
      "\u001b[32m[2023-04-22 22:27:03,017] [    INFO]\u001b[0m - Downloading ernie_3.0_medium_zh_vocab.txt from https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_medium_zh_vocab.txt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a3f345f4084bd1a0502013febe0b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/182k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-22 22:27:04,927] [    INFO]\u001b[0m - tokenizer config file saved in C:\\Users\\hjh\\.paddlenlp\\models\\ernie-3.0-medium-zh\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-22 22:27:04,928] [    INFO]\u001b[0m - Special tokens file saved in C:\\Users\\hjh\\.paddlenlp\\models\\ernie-3.0-medium-zh\\special_tokens_map.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"ernie-3.0-medium-zh\"   # ERNIE3.0 model\n",
    "num_classes = 28  # 28 classification mission\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_classes=num_classes)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNHyEHEH5h7_"
   },
   "source": [
    "## Process the raw data into a model-acceptable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "gHk1B5Wc5tav"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "\n",
    "from paddle.io import DataLoader, BatchSampler\n",
    "from paddlenlp.data import DataCollatorWithPadding\n",
    "\n",
    "# Data pre-processing function to convert text into integer sequences using a word splitter.\n",
    "def preprocess_function(examples, tokenizer, max_seq_length):\n",
    "    result = tokenizer(text=examples[\"text\"], max_seq_len=max_seq_length)\n",
    "    result[\"labels\"] = examples[\"labels\"]\n",
    "    return result\n",
    "\n",
    "trans_func = functools.partial(preprocess_function, tokenizer=tokenizer, max_seq_length=64)\n",
    "train_ds = train_ds.map(trans_func)\n",
    "test_ds = test_ds.map(trans_func)\n",
    "\n",
    "# function is constructed to extend the different length sequences to the maximum length of the data in the batch, and then stack the data.\n",
    "collate_fn = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# Define the BatchSampler, select the batch size and whether to randomly jumble the DataLoader.\n",
    "train_batch_sampler = BatchSampler(train_ds, batch_size=64, shuffle=True)\n",
    "test_batch_sampler = BatchSampler(test_ds, batch_size=32, shuffle=False)\n",
    "train_data_loader = DataLoader(dataset=train_ds, batch_sampler=train_batch_sampler, collate_fn=collate_fn)\n",
    "test_data_loader = DataLoader(dataset=test_ds, batch_sampler=test_batch_sampler, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EPA9Lq97O_3"
   },
   "source": [
    "## Define model validation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7HLrZrzK7RdI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
    "from paddle.metric import Metric\n",
    "\n",
    "# Customize MultiLabelReport evaluation metrics.\n",
    "class MultiLabelReport(Metric):\n",
    "    \"\"\"\n",
    "    AUC and F1 Score for multi-label text classification task.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name='MultiLabelReport', average='micro'):\n",
    "        super(MultiLabelReport, self).__init__()\n",
    "        self.average = average\n",
    "        self._name = name\n",
    "        self.reset()\n",
    "\n",
    "    def f1_score(self, y_prob):\n",
    "        '''\n",
    "        Returns the f1 score by searching the best threshhold\n",
    "        '''\n",
    "        best_score = 0\n",
    "        for threshold in [i * 0.01 for i in range(100)]:\n",
    "            self.y_pred = y_prob > threshold\n",
    "            score = sklearn.metrics.f1_score(y_pred=self.y_pred, y_true=self.y_true, average=self.average)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                precison = precision_score(y_pred=self.y_pred, y_true=self.y_true, average=self.average)\n",
    "                recall = recall_score(y_pred=self.y_pred, y_true=self.y_true, average=self.average)\n",
    "        return best_score, precison, recall\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets all of the metric state.\n",
    "        \"\"\"\n",
    "        self.y_prob = None\n",
    "        self.y_true = None\n",
    "\n",
    "    def update(self, probs, labels):\n",
    "        if self.y_prob is not None:\n",
    "            self.y_prob = np.append(self.y_prob, probs.numpy(), axis=0)\n",
    "        else:\n",
    "            self.y_prob = probs.numpy()\n",
    "        if self.y_true is not None:\n",
    "            self.y_true = np.append(self.y_true, labels.numpy(), axis=0)\n",
    "        else:\n",
    "            self.y_true = labels.numpy()\n",
    "\n",
    "    def accumulate(self):\n",
    "        auc = roc_auc_score(\n",
    "            y_score=self.y_prob, y_true=self.y_true, average=self.average)\n",
    "        f1_score, precison, recall = self.f1_score(y_prob=self.y_prob)\n",
    "        return auc, f1_score, precison, recall\n",
    "\n",
    "    def name(self):\n",
    "        \"\"\"\n",
    "        Returns metric name\n",
    "        \"\"\"\n",
    "        return self._name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H04sxVsF7lwJ"
   },
   "source": [
    "# Building the training model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLbmmDC38F1l"
   },
   "source": [
    "## Select an optimization strategy and run configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9yvG7sEc8QZj"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "# AdamW optimizer, cross-entropy loss function, custom MultiLabelReport evaluation metrics.\n",
    "optimizer = paddle.optimizer.AdamW(learning_rate=4e-5, parameters=model.parameters(), weight_decay=0.01)\n",
    "criterion = paddle.nn.BCEWithLogitsLoss()\n",
    "metric = MultiLabelReport()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evJ-MG798fyJ"
   },
   "source": [
    "## Model training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "D_97el-H8hc7"
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import numpy as np\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "# Build the validation set evaluate function.\n",
    "@paddle.no_grad()\n",
    "def evaluate(model, criterion, metric, data_loader, label_vocab, if_return_results=True):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    losses = []\n",
    "    results = []\n",
    "    for batch in data_loader:\n",
    "        input_ids, token_type_ids, labels = batch['input_ids'], batch['token_type_ids'], batch['labels']\n",
    "        logits = model(input_ids, token_type_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        probs = F.sigmoid(logits)\n",
    "        losses.append(loss.numpy())\n",
    "        metric.update(probs, labels)\n",
    "        if if_return_results:\n",
    "            probs = probs.tolist()\n",
    "            for prob in probs:\n",
    "                result = []\n",
    "                for c, pred in enumerate(prob):\n",
    "                    if pred > 0.5:\n",
    "                        result.append(label_vocab[c])\n",
    "                results.append(','.join(result))\n",
    "\n",
    "    auc, f1_score, precison, recall = metric.accumulate()\n",
    "    print(\"eval loss: %.5f, auc: %.5f, f1 score: %.5f, precison: %.5f, recall: %.5f\" %\n",
    "          (np.mean(losses), auc, f1_score, precison, recall))\n",
    "    model.train()\n",
    "    metric.reset()\n",
    "    if if_return_results:\n",
    "        return results\n",
    "    else:\n",
    "        return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8I8ToDtX87QQ",
    "outputId": "b05662b8-084b-448e-df2a-df0b705d6542",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 10, epoch: 1, batch: 10, loss: 0.33973, auc: 0.58098, f1 score: 0.10815, speed: 0.11 step/s\n",
      "global step 20, epoch: 1, batch: 20, loss: 0.25568, auc: 0.59821, f1 score: 0.12810, speed: 0.09 step/s\n",
      "global step 30, epoch: 1, batch: 30, loss: 0.21206, auc: 0.60622, f1 score: 0.13626, speed: 0.07 step/s\n",
      "global step 40, epoch: 1, batch: 40, loss: 0.19086, auc: 0.61803, f1 score: 0.14521, speed: 0.06 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-22 22:39:30,697] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.18245, auc: 0.73075, f1 score: 0.30401, precison: 0.32928, recall: 0.28235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-22 22:39:31,012] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-22 22:39:31,014] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 50, epoch: 1, batch: 50, loss: 0.17854, auc: 0.70201, f1 score: 0.28078, speed: 0.03 step/s\n",
      "global step 60, epoch: 1, batch: 60, loss: 0.16560, auc: 0.71011, f1 score: 0.29439, speed: 0.06 step/s\n",
      "global step 70, epoch: 1, batch: 70, loss: 0.16853, auc: 0.71820, f1 score: 0.30920, speed: 0.05 step/s\n",
      "global step 80, epoch: 1, batch: 80, loss: 0.14832, auc: 0.72184, f1 score: 0.31686, speed: 0.05 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-22 22:54:38,113] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.15534, auc: 0.76200, f1 score: 0.30404, precison: 0.32934, recall: 0.28235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-22 22:54:38,406] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-22 22:54:38,407] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 90, epoch: 1, batch: 90, loss: 0.16050, auc: 0.75163, f1 score: 0.29458, speed: 0.03 step/s\n",
      "global step 100, epoch: 1, batch: 100, loss: 0.14958, auc: 0.75566, f1 score: 0.29330, speed: 0.06 step/s\n",
      "global step 110, epoch: 1, batch: 110, loss: 0.16484, auc: 0.75195, f1 score: 0.29021, speed: 0.05 step/s\n",
      "global step 120, epoch: 1, batch: 120, loss: 0.15529, auc: 0.75316, f1 score: 0.29294, speed: 0.05 step/s\n",
      "eval loss: 0.15037, auc: 0.77164, f1 score: 0.30401, precison: 0.32928, recall: 0.28235\n",
      "global step 130, epoch: 1, batch: 130, loss: 0.15833, auc: 0.76187, f1 score: 0.29078, speed: 0.03 step/s\n",
      "global step 140, epoch: 1, batch: 140, loss: 0.13093, auc: 0.75767, f1 score: 0.29603, speed: 0.05 step/s\n",
      "global step 150, epoch: 1, batch: 150, loss: 0.14364, auc: 0.76291, f1 score: 0.30743, speed: 0.05 step/s\n",
      "global step 160, epoch: 1, batch: 160, loss: 0.15443, auc: 0.76588, f1 score: 0.31198, speed: 0.06 step/s\n",
      "eval loss: 0.14905, auc: 0.77401, f1 score: 0.30401, precison: 0.32928, recall: 0.28235\n",
      "global step 170, epoch: 1, batch: 170, loss: 0.15495, auc: 0.75869, f1 score: 0.28083, speed: 0.03 step/s\n",
      "global step 180, epoch: 1, batch: 180, loss: 0.14671, auc: 0.76369, f1 score: 0.29401, speed: 0.06 step/s\n",
      "global step 190, epoch: 1, batch: 190, loss: 0.14186, auc: 0.76118, f1 score: 0.29046, speed: 0.06 step/s\n",
      "global step 200, epoch: 1, batch: 200, loss: 0.14084, auc: 0.76218, f1 score: 0.29515, speed: 0.06 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-22 23:40:37,046] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.14794, auc: 0.77577, f1 score: 0.30765, precison: 0.34846, recall: 0.27540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-22 23:40:37,339] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-22 23:40:37,343] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 210, epoch: 1, batch: 210, loss: 0.14091, auc: 0.76609, f1 score: 0.29025, speed: 0.03 step/s\n",
      "global step 220, epoch: 1, batch: 220, loss: 0.14824, auc: 0.76482, f1 score: 0.29549, speed: 0.07 step/s\n",
      "global step 230, epoch: 1, batch: 230, loss: 0.14387, auc: 0.76759, f1 score: 0.30265, speed: 0.07 step/s\n",
      "global step 240, epoch: 1, batch: 240, loss: 0.14159, auc: 0.76975, f1 score: 0.30624, speed: 0.07 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-22 23:53:31,366] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.14193, auc: 0.79162, f1 score: 0.37034, precison: 0.49694, recall: 0.29515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-22 23:53:31,642] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-22 23:53:31,644] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 250, epoch: 1, batch: 250, loss: 0.15481, auc: 0.80076, f1 score: 0.36083, speed: 0.03 step/s\n",
      "global step 260, epoch: 1, batch: 260, loss: 0.15375, auc: 0.80378, f1 score: 0.36571, speed: 0.07 step/s\n",
      "global step 270, epoch: 1, batch: 270, loss: 0.15641, auc: 0.80677, f1 score: 0.36792, speed: 0.08 step/s\n",
      "global step 280, epoch: 1, batch: 280, loss: 0.12451, auc: 0.80965, f1 score: 0.37976, speed: 0.07 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 00:05:42,116] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.13238, auc: 0.82319, f1 score: 0.44929, precison: 0.50900, recall: 0.40212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 00:05:42,392] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 00:05:42,393] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 290, epoch: 1, batch: 290, loss: 0.13271, auc: 0.81325, f1 score: 0.43447, speed: 0.03 step/s\n",
      "global step 300, epoch: 1, batch: 300, loss: 0.12280, auc: 0.82875, f1 score: 0.43279, speed: 0.07 step/s\n",
      "global step 310, epoch: 1, batch: 310, loss: 0.13638, auc: 0.83444, f1 score: 0.43371, speed: 0.08 step/s\n",
      "global step 320, epoch: 1, batch: 320, loss: 0.13253, auc: 0.83455, f1 score: 0.44184, speed: 0.07 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 00:17:39,586] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.12736, auc: 0.83754, f1 score: 0.46042, precison: 0.45948, recall: 0.46137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 00:17:39,874] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 00:17:39,875] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 330, epoch: 1, batch: 330, loss: 0.12752, auc: 0.84054, f1 score: 0.44642, speed: 0.03 step/s\n",
      "global step 340, epoch: 1, batch: 340, loss: 0.11000, auc: 0.84163, f1 score: 0.45316, speed: 0.08 step/s\n",
      "global step 350, epoch: 1, batch: 350, loss: 0.13098, auc: 0.84094, f1 score: 0.46105, speed: 0.08 step/s\n",
      "global step 360, epoch: 1, batch: 360, loss: 0.11913, auc: 0.84338, f1 score: 0.46268, speed: 0.08 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 00:29:06,781] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.12248, auc: 0.85363, f1 score: 0.47531, precison: 0.50345, recall: 0.45015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 00:29:07,073] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 00:29:07,074] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 370, epoch: 1, batch: 370, loss: 0.11921, auc: 0.84703, f1 score: 0.45833, speed: 0.03 step/s\n",
      "global step 380, epoch: 1, batch: 380, loss: 0.12738, auc: 0.85712, f1 score: 0.48227, speed: 0.08 step/s\n",
      "global step 390, epoch: 1, batch: 390, loss: 0.11982, auc: 0.85878, f1 score: 0.48742, speed: 0.07 step/s\n",
      "global step 400, epoch: 1, batch: 400, loss: 0.12346, auc: 0.86099, f1 score: 0.48468, speed: 0.08 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 00:40:39,946] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.11826, auc: 0.87630, f1 score: 0.50188, precison: 0.54819, recall: 0.46279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 00:40:40,225] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 00:40:40,226] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 410, epoch: 1, batch: 410, loss: 0.12456, auc: 0.85622, f1 score: 0.47312, speed: 0.03 step/s\n",
      "global step 420, epoch: 1, batch: 420, loss: 0.11598, auc: 0.85842, f1 score: 0.48148, speed: 0.08 step/s\n",
      "global step 430, epoch: 1, batch: 430, loss: 0.13611, auc: 0.86075, f1 score: 0.49426, speed: 0.07 step/s\n",
      "global step 440, epoch: 1, batch: 440, loss: 0.12074, auc: 0.86424, f1 score: 0.48944, speed: 0.08 step/s\n",
      "eval loss: 0.11543, auc: 0.88757, f1 score: 0.49894, precison: 0.53843, recall: 0.46484\n",
      "global step 450, epoch: 1, batch: 450, loss: 0.10241, auc: 0.87634, f1 score: 0.51448, speed: 0.03 step/s\n",
      "global step 460, epoch: 1, batch: 460, loss: 0.12172, auc: 0.87406, f1 score: 0.50169, speed: 0.08 step/s\n",
      "global step 470, epoch: 1, batch: 470, loss: 0.11989, auc: 0.87878, f1 score: 0.49596, speed: 0.08 step/s\n",
      "global step 480, epoch: 1, batch: 480, loss: 0.12308, auc: 0.88138, f1 score: 0.49556, speed: 0.08 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 01:03:28,797] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.11262, auc: 0.89521, f1 score: 0.51561, precison: 0.53268, recall: 0.49960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 01:03:29,094] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 01:03:29,095] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 490, epoch: 1, batch: 490, loss: 0.12267, auc: 0.89061, f1 score: 0.51885, speed: 0.03 step/s\n",
      "global step 500, epoch: 1, batch: 500, loss: 0.12672, auc: 0.88613, f1 score: 0.48586, speed: 0.09 step/s\n",
      "global step 510, epoch: 1, batch: 510, loss: 0.11888, auc: 0.88572, f1 score: 0.49436, speed: 0.09 step/s\n",
      "global step 520, epoch: 1, batch: 520, loss: 0.12615, auc: 0.88777, f1 score: 0.49938, speed: 0.08 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 01:14:19,667] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.11094, auc: 0.90045, f1 score: 0.52014, precison: 0.53499, recall: 0.50608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 01:14:19,941] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 01:14:19,942] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 530, epoch: 1, batch: 530, loss: 0.12170, auc: 0.88394, f1 score: 0.49752, speed: 0.03 step/s\n",
      "global step 540, epoch: 1, batch: 540, loss: 0.10997, auc: 0.89139, f1 score: 0.50780, speed: 0.08 step/s\n",
      "global step 550, epoch: 1, batch: 550, loss: 0.12662, auc: 0.89185, f1 score: 0.51054, speed: 0.08 step/s\n",
      "global step 560, epoch: 1, batch: 560, loss: 0.12105, auc: 0.88916, f1 score: 0.50811, speed: 0.08 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 01:25:12,123] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.10902, auc: 0.90653, f1 score: 0.52395, precison: 0.56427, recall: 0.48902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 01:25:12,416] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 01:25:12,417] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 570, epoch: 1, batch: 570, loss: 0.11167, auc: 0.89953, f1 score: 0.49703, speed: 0.03 step/s\n",
      "global step 580, epoch: 1, batch: 580, loss: 0.11684, auc: 0.90205, f1 score: 0.50082, speed: 0.08 step/s\n",
      "global step 590, epoch: 1, batch: 590, loss: 0.11763, auc: 0.90552, f1 score: 0.51227, speed: 0.08 step/s\n",
      "global step 600, epoch: 1, batch: 600, loss: 0.09869, auc: 0.90654, f1 score: 0.51682, speed: 0.08 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 01:36:24,935] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.10762, auc: 0.90999, f1 score: 0.52812, precison: 0.54974, recall: 0.50814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 01:36:25,229] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 01:36:25,230] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 610, epoch: 1, batch: 610, loss: 0.10949, auc: 0.90282, f1 score: 0.52122, speed: 0.03 step/s\n",
      "global step 620, epoch: 1, batch: 620, loss: 0.09903, auc: 0.89890, f1 score: 0.51854, speed: 0.08 step/s\n",
      "global step 630, epoch: 1, batch: 630, loss: 0.11084, auc: 0.90090, f1 score: 0.52359, speed: 0.09 step/s\n",
      "global step 640, epoch: 1, batch: 640, loss: 0.11798, auc: 0.90234, f1 score: 0.51709, speed: 0.08 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 01:47:23,980] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.10514, auc: 0.91483, f1 score: 0.53416, precison: 0.52277, recall: 0.54606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 01:47:24,252] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 01:47:24,253] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 650, epoch: 1, batch: 650, loss: 0.10802, auc: 0.91049, f1 score: 0.52610, speed: 0.03 step/s\n",
      "global step 660, epoch: 1, batch: 660, loss: 0.10138, auc: 0.90881, f1 score: 0.53426, speed: 0.08 step/s\n",
      "global step 670, epoch: 1, batch: 670, loss: 0.11411, auc: 0.90609, f1 score: 0.52409, speed: 0.09 step/s\n",
      "global step 680, epoch: 1, batch: 680, loss: 0.11521, auc: 0.90639, f1 score: 0.51865, speed: 0.09 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 01:58:13,998] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.10386, auc: 0.91406, f1 score: 0.54496, precison: 0.57418, recall: 0.51857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 01:58:14,276] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 01:58:14,277] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 690, epoch: 1, batch: 690, loss: 0.10404, auc: 0.91042, f1 score: 0.53189, speed: 0.03 step/s\n",
      "global step 700, epoch: 1, batch: 700, loss: 0.09252, auc: 0.91313, f1 score: 0.53299, speed: 0.09 step/s\n",
      "global step 710, epoch: 1, batch: 710, loss: 0.10700, auc: 0.91464, f1 score: 0.53069, speed: 0.09 step/s\n",
      "global step 720, epoch: 1, batch: 720, loss: 0.09621, auc: 0.91535, f1 score: 0.53327, speed: 0.09 step/s\n",
      "eval loss: 0.10395, auc: 0.91347, f1 score: 0.54186, precison: 0.56270, recall: 0.52252\n",
      "global step 730, epoch: 1, batch: 730, loss: 0.10461, auc: 0.91367, f1 score: 0.51847, speed: 0.03 step/s\n",
      "global step 740, epoch: 1, batch: 740, loss: 0.09623, auc: 0.91616, f1 score: 0.53540, speed: 0.09 step/s\n",
      "global step 750, epoch: 1, batch: 750, loss: 0.09653, auc: 0.91354, f1 score: 0.52752, speed: 0.09 step/s\n",
      "global step 760, epoch: 1, batch: 760, loss: 0.10841, auc: 0.91355, f1 score: 0.52381, speed: 0.09 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 02:19:28,846] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.10205, auc: 0.92164, f1 score: 0.55109, precison: 0.56998, recall: 0.53342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 02:19:29,116] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 02:19:29,117] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 770, epoch: 2, batch: 6, loss: 0.10844, auc: 0.92411, f1 score: 0.56260, speed: 0.04 step/s\n",
      "global step 780, epoch: 2, batch: 16, loss: 0.10202, auc: 0.91677, f1 score: 0.54164, speed: 0.09 step/s\n",
      "global step 790, epoch: 2, batch: 26, loss: 0.11338, auc: 0.91523, f1 score: 0.54127, speed: 0.08 step/s\n",
      "global step 800, epoch: 2, batch: 36, loss: 0.10230, auc: 0.91580, f1 score: 0.54289, speed: 0.09 step/s\n",
      "eval loss: 0.10317, auc: 0.91560, f1 score: 0.53898, precison: 0.54566, recall: 0.53247\n",
      "global step 810, epoch: 2, batch: 46, loss: 0.08976, auc: 0.91704, f1 score: 0.55010, speed: 0.03 step/s\n",
      "global step 820, epoch: 2, batch: 56, loss: 0.09371, auc: 0.91377, f1 score: 0.54635, speed: 0.09 step/s\n",
      "global step 830, epoch: 2, batch: 66, loss: 0.09462, auc: 0.91785, f1 score: 0.54481, speed: 0.08 step/s\n",
      "global step 840, epoch: 2, batch: 76, loss: 0.11507, auc: 0.91954, f1 score: 0.54449, speed: 0.09 step/s\n",
      "eval loss: 0.09995, auc: 0.92400, f1 score: 0.54887, precison: 0.53748, recall: 0.56075\n",
      "global step 850, epoch: 2, batch: 86, loss: 0.10763, auc: 0.93118, f1 score: 0.57253, speed: 0.03 step/s\n",
      "global step 860, epoch: 2, batch: 96, loss: 0.10629, auc: 0.92910, f1 score: 0.56053, speed: 0.09 step/s\n",
      "global step 870, epoch: 2, batch: 106, loss: 0.11983, auc: 0.92550, f1 score: 0.55102, speed: 0.09 step/s\n",
      "global step 880, epoch: 2, batch: 116, loss: 0.11005, auc: 0.92368, f1 score: 0.54265, speed: 0.09 step/s\n",
      "eval loss: 0.09972, auc: 0.92607, f1 score: 0.54888, precison: 0.54252, recall: 0.55538\n",
      "global step 890, epoch: 2, batch: 126, loss: 0.11347, auc: 0.93262, f1 score: 0.56435, speed: 0.03 step/s\n",
      "global step 900, epoch: 2, batch: 136, loss: 0.08972, auc: 0.92974, f1 score: 0.55961, speed: 0.09 step/s\n",
      "global step 910, epoch: 2, batch: 146, loss: 0.10362, auc: 0.92746, f1 score: 0.55418, speed: 0.09 step/s\n",
      "global step 920, epoch: 2, batch: 156, loss: 0.09337, auc: 0.92806, f1 score: 0.55642, speed: 0.08 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 03:01:59,139] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.09848, auc: 0.92482, f1 score: 0.55472, precison: 0.53792, recall: 0.57260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 03:01:59,404] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 03:01:59,405] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 930, epoch: 2, batch: 166, loss: 0.08476, auc: 0.92921, f1 score: 0.54523, speed: 0.03 step/s\n",
      "global step 940, epoch: 2, batch: 176, loss: 0.08700, auc: 0.92575, f1 score: 0.55276, speed: 0.08 step/s\n",
      "global step 950, epoch: 2, batch: 186, loss: 0.10809, auc: 0.92531, f1 score: 0.56009, speed: 0.08 step/s\n",
      "global step 960, epoch: 2, batch: 196, loss: 0.10085, auc: 0.92493, f1 score: 0.55908, speed: 0.08 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 03:13:12,258] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.09719, auc: 0.93004, f1 score: 0.56197, precison: 0.58062, recall: 0.54448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 03:13:12,554] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 03:13:12,555] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 970, epoch: 2, batch: 206, loss: 0.09602, auc: 0.92372, f1 score: 0.53887, speed: 0.03 step/s\n",
      "global step 980, epoch: 2, batch: 216, loss: 0.10809, auc: 0.92515, f1 score: 0.54478, speed: 0.09 step/s\n",
      "global step 990, epoch: 2, batch: 226, loss: 0.10495, auc: 0.92708, f1 score: 0.55743, speed: 0.08 step/s\n",
      "global step 1000, epoch: 2, batch: 236, loss: 0.09704, auc: 0.92698, f1 score: 0.55460, speed: 0.08 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 03:24:09,406] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.09731, auc: 0.92738, f1 score: 0.56413, precison: 0.55620, recall: 0.57229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 03:24:09,707] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 03:24:09,708] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 1010, epoch: 2, batch: 246, loss: 0.11226, auc: 0.91461, f1 score: 0.55370, speed: 0.03 step/s\n",
      "global step 1020, epoch: 2, batch: 256, loss: 0.10435, auc: 0.91913, f1 score: 0.55000, speed: 0.08 step/s\n",
      "global step 1030, epoch: 2, batch: 266, loss: 0.08928, auc: 0.92444, f1 score: 0.55674, speed: 0.08 step/s\n",
      "global step 1040, epoch: 2, batch: 276, loss: 0.11603, auc: 0.92711, f1 score: 0.55945, speed: 0.08 step/s\n",
      "eval loss: 0.09722, auc: 0.93089, f1 score: 0.55687, precison: 0.53112, recall: 0.58524\n",
      "global step 1050, epoch: 2, batch: 286, loss: 0.09576, auc: 0.93263, f1 score: 0.55053, speed: 0.03 step/s\n",
      "global step 1060, epoch: 2, batch: 296, loss: 0.12085, auc: 0.92917, f1 score: 0.54707, speed: 0.09 step/s\n",
      "global step 1070, epoch: 2, batch: 306, loss: 0.09942, auc: 0.92863, f1 score: 0.55863, speed: 0.09 step/s\n",
      "global step 1080, epoch: 2, batch: 316, loss: 0.09269, auc: 0.92945, f1 score: 0.56273, speed: 0.08 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 03:46:15,268] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.09600, auc: 0.93222, f1 score: 0.56592, precison: 0.55729, recall: 0.57481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 03:46:15,565] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 03:46:15,566] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 1090, epoch: 2, batch: 326, loss: 0.10641, auc: 0.92870, f1 score: 0.57812, speed: 0.03 step/s\n",
      "global step 1100, epoch: 2, batch: 336, loss: 0.10444, auc: 0.92753, f1 score: 0.56792, speed: 0.08 step/s\n",
      "global step 1110, epoch: 2, batch: 346, loss: 0.08754, auc: 0.92778, f1 score: 0.55910, speed: 0.09 step/s\n",
      "global step 1120, epoch: 2, batch: 356, loss: 0.10154, auc: 0.92947, f1 score: 0.56044, speed: 0.09 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 03:57:10,668] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.09556, auc: 0.93318, f1 score: 0.57291, precison: 0.57755, recall: 0.56834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 03:57:10,957] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 03:57:10,958] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 1130, epoch: 2, batch: 366, loss: 0.10402, auc: 0.92876, f1 score: 0.56154, speed: 0.03 step/s\n",
      "global step 1140, epoch: 2, batch: 376, loss: 0.08200, auc: 0.93196, f1 score: 0.57559, speed: 0.09 step/s\n",
      "global step 1150, epoch: 2, batch: 386, loss: 0.09881, auc: 0.93160, f1 score: 0.56827, speed: 0.08 step/s\n",
      "global step 1160, epoch: 2, batch: 396, loss: 0.08815, auc: 0.93231, f1 score: 0.57452, speed: 0.08 step/s\n",
      "eval loss: 0.09519, auc: 0.93412, f1 score: 0.56646, precison: 0.59520, recall: 0.54037\n",
      "global step 1170, epoch: 2, batch: 406, loss: 0.10119, auc: 0.93027, f1 score: 0.55752, speed: 0.03 step/s\n",
      "global step 1180, epoch: 2, batch: 416, loss: 0.09236, auc: 0.92888, f1 score: 0.55353, speed: 0.09 step/s\n",
      "global step 1190, epoch: 2, batch: 426, loss: 0.08925, auc: 0.92875, f1 score: 0.55161, speed: 0.09 step/s\n",
      "global step 1200, epoch: 2, batch: 436, loss: 0.09824, auc: 0.93061, f1 score: 0.55501, speed: 0.08 step/s\n",
      "eval loss: 0.09433, auc: 0.93595, f1 score: 0.57221, precison: 0.55107, recall: 0.59504\n",
      "global step 1210, epoch: 2, batch: 446, loss: 0.09216, auc: 0.92983, f1 score: 0.56305, speed: 0.03 step/s\n",
      "global step 1220, epoch: 2, batch: 456, loss: 0.10313, auc: 0.92952, f1 score: 0.56173, speed: 0.09 step/s\n",
      "global step 1230, epoch: 2, batch: 466, loss: 0.10096, auc: 0.93311, f1 score: 0.57305, speed: 0.08 step/s\n",
      "global step 1240, epoch: 2, batch: 476, loss: 0.10908, auc: 0.93162, f1 score: 0.56482, speed: 0.09 step/s\n",
      "eval loss: 0.09457, auc: 0.93658, f1 score: 0.56854, precison: 0.56858, recall: 0.56849\n",
      "global step 1250, epoch: 2, batch: 486, loss: 0.09857, auc: 0.92528, f1 score: 0.55523, speed: 0.03 step/s\n",
      "global step 1260, epoch: 2, batch: 496, loss: 0.10019, auc: 0.93155, f1 score: 0.56684, speed: 0.09 step/s\n",
      "global step 1270, epoch: 2, batch: 506, loss: 0.09969, auc: 0.93222, f1 score: 0.57093, speed: 0.09 step/s\n",
      "global step 1280, epoch: 2, batch: 516, loss: 0.07949, auc: 0.93311, f1 score: 0.56988, speed: 0.09 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 04:40:21,488] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.09411, auc: 0.93590, f1 score: 0.57298, precison: 0.55680, recall: 0.59014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 04:40:21,771] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 04:40:21,772] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 1290, epoch: 2, batch: 526, loss: 0.08289, auc: 0.93551, f1 score: 0.57234, speed: 0.03 step/s\n",
      "global step 1300, epoch: 2, batch: 536, loss: 0.08581, auc: 0.93825, f1 score: 0.57341, speed: 0.08 step/s\n",
      "global step 1310, epoch: 2, batch: 546, loss: 0.09475, auc: 0.93901, f1 score: 0.57258, speed: 0.09 step/s\n",
      "global step 1320, epoch: 2, batch: 556, loss: 0.11160, auc: 0.93572, f1 score: 0.56853, speed: 0.09 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 04:51:10,796] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.09324, auc: 0.93825, f1 score: 0.57855, precison: 0.57961, recall: 0.57750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 04:51:11,072] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 04:51:11,073] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 1330, epoch: 2, batch: 566, loss: 0.09847, auc: 0.93492, f1 score: 0.57676, speed: 0.03 step/s\n",
      "global step 1340, epoch: 2, batch: 576, loss: 0.08244, auc: 0.93416, f1 score: 0.57404, speed: 0.09 step/s\n",
      "global step 1350, epoch: 2, batch: 586, loss: 0.10232, auc: 0.93143, f1 score: 0.56457, speed: 0.09 step/s\n",
      "global step 1360, epoch: 2, batch: 596, loss: 0.09079, auc: 0.93341, f1 score: 0.57133, speed: 0.08 step/s\n",
      "eval loss: 0.09372, auc: 0.93801, f1 score: 0.57392, precison: 0.55590, recall: 0.59314\n",
      "global step 1370, epoch: 2, batch: 606, loss: 0.08789, auc: 0.93409, f1 score: 0.56639, speed: 0.03 step/s\n",
      "global step 1380, epoch: 2, batch: 616, loss: 0.09389, auc: 0.93475, f1 score: 0.56446, speed: 0.09 step/s\n",
      "global step 1390, epoch: 2, batch: 626, loss: 0.08363, auc: 0.93574, f1 score: 0.57059, speed: 0.09 step/s\n",
      "global step 1400, epoch: 2, batch: 636, loss: 0.10816, auc: 0.93514, f1 score: 0.56690, speed: 0.09 step/s\n",
      "eval loss: 0.09348, auc: 0.93836, f1 score: 0.57465, precison: 0.56921, recall: 0.58019\n",
      "global step 1410, epoch: 2, batch: 646, loss: 0.10442, auc: 0.93034, f1 score: 0.56140, speed: 0.03 step/s\n",
      "global step 1420, epoch: 2, batch: 656, loss: 0.07539, auc: 0.93368, f1 score: 0.56418, speed: 0.09 step/s\n",
      "global step 1430, epoch: 2, batch: 666, loss: 0.08408, auc: 0.93486, f1 score: 0.56600, speed: 0.08 step/s\n",
      "global step 1440, epoch: 2, batch: 676, loss: 0.08813, auc: 0.93709, f1 score: 0.57609, speed: 0.08 step/s\n",
      "eval loss: 0.09353, auc: 0.93707, f1 score: 0.57346, precison: 0.56795, recall: 0.57908\n",
      "global step 1450, epoch: 2, batch: 686, loss: 0.08256, auc: 0.94117, f1 score: 0.57234, speed: 0.03 step/s\n",
      "global step 1460, epoch: 2, batch: 696, loss: 0.09977, auc: 0.93902, f1 score: 0.57062, speed: 0.09 step/s\n",
      "global step 1470, epoch: 2, batch: 706, loss: 0.08986, auc: 0.93962, f1 score: 0.57441, speed: 0.08 step/s\n",
      "global step 1480, epoch: 2, batch: 716, loss: 0.08769, auc: 0.93962, f1 score: 0.57584, speed: 0.09 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 05:33:41,768] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.09231, auc: 0.93868, f1 score: 0.57943, precison: 0.57852, recall: 0.58034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 05:33:42,054] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 05:33:42,055] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 1490, epoch: 2, batch: 726, loss: 0.08085, auc: 0.93831, f1 score: 0.59275, speed: 0.03 step/s\n",
      "global step 1500, epoch: 2, batch: 736, loss: 0.09041, auc: 0.93831, f1 score: 0.58967, speed: 0.09 step/s\n",
      "global step 1510, epoch: 2, batch: 746, loss: 0.09670, auc: 0.93995, f1 score: 0.58618, speed: 0.09 step/s\n",
      "global step 1520, epoch: 2, batch: 756, loss: 0.10940, auc: 0.93901, f1 score: 0.58296, speed: 0.08 step/s\n",
      "eval loss: 0.09291, auc: 0.93872, f1 score: 0.57539, precison: 0.56735, recall: 0.58366\n",
      "global step 1530, epoch: 3, batch: 2, loss: 0.09207, auc: 0.93996, f1 score: 0.57701, speed: 0.03 step/s\n",
      "global step 1540, epoch: 3, batch: 12, loss: 0.08244, auc: 0.94047, f1 score: 0.58845, speed: 0.09 step/s\n",
      "global step 1550, epoch: 3, batch: 22, loss: 0.07453, auc: 0.94432, f1 score: 0.58812, speed: 0.08 step/s\n",
      "global step 1560, epoch: 3, batch: 32, loss: 0.07976, auc: 0.94297, f1 score: 0.57789, speed: 0.08 step/s\n",
      "eval loss: 0.09320, auc: 0.94056, f1 score: 0.56164, precison: 0.56111, recall: 0.56217\n",
      "global step 1570, epoch: 3, batch: 42, loss: 0.08359, auc: 0.94751, f1 score: 0.59334, speed: 0.03 step/s\n",
      "global step 1580, epoch: 3, batch: 52, loss: 0.08301, auc: 0.94676, f1 score: 0.58037, speed: 0.09 step/s\n",
      "global step 1590, epoch: 3, batch: 62, loss: 0.09201, auc: 0.94791, f1 score: 0.59274, speed: 0.08 step/s\n",
      "global step 1600, epoch: 3, batch: 72, loss: 0.08022, auc: 0.94928, f1 score: 0.59960, speed: 0.08 step/s\n",
      "eval loss: 0.09158, auc: 0.94222, f1 score: 0.57935, precison: 0.56040, recall: 0.59962\n",
      "global step 1610, epoch: 3, batch: 82, loss: 0.07251, auc: 0.94704, f1 score: 0.62717, speed: 0.03 step/s\n",
      "global step 1620, epoch: 3, batch: 92, loss: 0.10374, auc: 0.94790, f1 score: 0.60909, speed: 0.09 step/s\n",
      "global step 1630, epoch: 3, batch: 102, loss: 0.08273, auc: 0.94872, f1 score: 0.61322, speed: 0.09 step/s\n",
      "global step 1640, epoch: 3, batch: 112, loss: 0.09748, auc: 0.94736, f1 score: 0.60790, speed: 0.08 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 06:17:01,343] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.09083, auc: 0.94243, f1 score: 0.58528, precison: 0.56626, recall: 0.60562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 06:17:01,630] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 06:17:01,631] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 1650, epoch: 3, batch: 122, loss: 0.08573, auc: 0.93660, f1 score: 0.60714, speed: 0.03 step/s\n",
      "global step 1660, epoch: 3, batch: 132, loss: 0.08995, auc: 0.94282, f1 score: 0.61286, speed: 0.09 step/s\n",
      "global step 1670, epoch: 3, batch: 142, loss: 0.07296, auc: 0.94466, f1 score: 0.60405, speed: 0.09 step/s\n",
      "global step 1680, epoch: 3, batch: 152, loss: 0.09429, auc: 0.94623, f1 score: 0.60549, speed: 0.09 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 06:27:25,846] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.09173, auc: 0.93951, f1 score: 0.58577, precison: 0.57546, recall: 0.59646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 06:27:26,111] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 06:27:26,112] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 1690, epoch: 3, batch: 162, loss: 0.07336, auc: 0.94960, f1 score: 0.60657, speed: 0.03 step/s\n",
      "global step 1700, epoch: 3, batch: 172, loss: 0.10040, auc: 0.95086, f1 score: 0.61466, speed: 0.09 step/s\n",
      "global step 1710, epoch: 3, batch: 182, loss: 0.08368, auc: 0.94947, f1 score: 0.61713, speed: 0.08 step/s\n",
      "global step 1720, epoch: 3, batch: 192, loss: 0.08639, auc: 0.94964, f1 score: 0.61562, speed: 0.08 step/s\n",
      "eval loss: 0.09199, auc: 0.94025, f1 score: 0.57879, precison: 0.57897, recall: 0.57861\n",
      "global step 1730, epoch: 3, batch: 202, loss: 0.09061, auc: 0.95568, f1 score: 0.63584, speed: 0.03 step/s\n",
      "global step 1740, epoch: 3, batch: 212, loss: 0.09990, auc: 0.95517, f1 score: 0.62241, speed: 0.09 step/s\n",
      "global step 1750, epoch: 3, batch: 222, loss: 0.07948, auc: 0.95165, f1 score: 0.61784, speed: 0.09 step/s\n",
      "global step 1760, epoch: 3, batch: 232, loss: 0.08471, auc: 0.95296, f1 score: 0.61653, speed: 0.09 step/s\n",
      "eval loss: 0.09123, auc: 0.94098, f1 score: 0.58476, precison: 0.58147, recall: 0.58809\n",
      "global step 1770, epoch: 3, batch: 242, loss: 0.10086, auc: 0.94535, f1 score: 0.57531, speed: 0.03 step/s\n",
      "global step 1780, epoch: 3, batch: 252, loss: 0.08262, auc: 0.94636, f1 score: 0.57615, speed: 0.09 step/s\n",
      "global step 1790, epoch: 3, batch: 262, loss: 0.08822, auc: 0.94453, f1 score: 0.56180, speed: 0.09 step/s\n",
      "global step 1800, epoch: 3, batch: 272, loss: 0.09187, auc: 0.94375, f1 score: 0.56716, speed: 0.09 step/s\n",
      "eval loss: 0.09137, auc: 0.94298, f1 score: 0.57372, precison: 0.56149, recall: 0.58651\n",
      "global step 1810, epoch: 3, batch: 282, loss: 0.08883, auc: 0.94609, f1 score: 0.61585, speed: 0.03 step/s\n",
      "global step 1820, epoch: 3, batch: 292, loss: 0.07352, auc: 0.95182, f1 score: 0.60878, speed: 0.09 step/s\n",
      "global step 1830, epoch: 3, batch: 302, loss: 0.10154, auc: 0.94789, f1 score: 0.60100, speed: 0.09 step/s\n",
      "global step 1840, epoch: 3, batch: 312, loss: 0.10811, auc: 0.94717, f1 score: 0.59551, speed: 0.09 step/s\n",
      "eval loss: 0.09131, auc: 0.94149, f1 score: 0.58027, precison: 0.55431, recall: 0.60878\n",
      "global step 1850, epoch: 3, batch: 322, loss: 0.08251, auc: 0.94651, f1 score: 0.60568, speed: 0.03 step/s\n",
      "global step 1860, epoch: 3, batch: 332, loss: 0.09172, auc: 0.94692, f1 score: 0.59576, speed: 0.08 step/s\n",
      "global step 1870, epoch: 3, batch: 342, loss: 0.08015, auc: 0.94390, f1 score: 0.58746, speed: 0.09 step/s\n",
      "global step 1880, epoch: 3, batch: 352, loss: 0.08326, auc: 0.94553, f1 score: 0.59292, speed: 0.09 step/s\n",
      "eval loss: 0.09151, auc: 0.94219, f1 score: 0.58163, precison: 0.56232, recall: 0.60231\n",
      "global step 1890, epoch: 3, batch: 362, loss: 0.07808, auc: 0.95394, f1 score: 0.61955, speed: 0.03 step/s\n",
      "global step 1900, epoch: 3, batch: 372, loss: 0.09228, auc: 0.94897, f1 score: 0.59924, speed: 0.09 step/s\n",
      "global step 1910, epoch: 3, batch: 382, loss: 0.08115, auc: 0.94830, f1 score: 0.60647, speed: 0.08 step/s\n",
      "global step 1920, epoch: 3, batch: 392, loss: 0.09109, auc: 0.94765, f1 score: 0.60720, speed: 0.08 step/s\n",
      "eval loss: 0.09265, auc: 0.94133, f1 score: 0.56682, precison: 0.55861, recall: 0.57529\n",
      "global step 1930, epoch: 3, batch: 402, loss: 0.08058, auc: 0.94597, f1 score: 0.60162, speed: 0.03 step/s\n",
      "global step 1940, epoch: 3, batch: 412, loss: 0.07884, auc: 0.94492, f1 score: 0.62198, speed: 0.09 step/s\n",
      "global step 1950, epoch: 3, batch: 422, loss: 0.08541, auc: 0.94583, f1 score: 0.61246, speed: 0.09 step/s\n",
      "global step 1960, epoch: 3, batch: 432, loss: 0.09139, auc: 0.94588, f1 score: 0.61429, speed: 0.08 step/s\n",
      "eval loss: 0.09268, auc: 0.94241, f1 score: 0.56860, precison: 0.56650, recall: 0.57071\n",
      "global step 1970, epoch: 3, batch: 442, loss: 0.09113, auc: 0.93950, f1 score: 0.56327, speed: 0.03 step/s\n",
      "global step 1980, epoch: 3, batch: 452, loss: 0.08230, auc: 0.94259, f1 score: 0.56836, speed: 0.09 step/s\n",
      "global step 1990, epoch: 3, batch: 462, loss: 0.08082, auc: 0.94562, f1 score: 0.58150, speed: 0.09 step/s\n",
      "global step 2000, epoch: 3, batch: 472, loss: 0.09602, auc: 0.94762, f1 score: 0.59001, speed: 0.08 step/s\n",
      "eval loss: 0.09066, auc: 0.94281, f1 score: 0.58347, precison: 0.58187, recall: 0.58508\n",
      "global step 2010, epoch: 3, batch: 482, loss: 0.07400, auc: 0.93998, f1 score: 0.60887, speed: 0.03 step/s\n",
      "global step 2020, epoch: 3, batch: 492, loss: 0.07788, auc: 0.94277, f1 score: 0.59646, speed: 0.09 step/s\n",
      "global step 2030, epoch: 3, batch: 502, loss: 0.07623, auc: 0.94859, f1 score: 0.60308, speed: 0.09 step/s\n",
      "global step 2040, epoch: 3, batch: 512, loss: 0.10196, auc: 0.94854, f1 score: 0.59866, speed: 0.09 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 08:03:56,850] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.09033, auc: 0.94178, f1 score: 0.58695, precison: 0.57524, recall: 0.59915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 08:03:57,113] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 08:03:57,114] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 2050, epoch: 3, batch: 522, loss: 0.10051, auc: 0.95150, f1 score: 0.61315, speed: 0.03 step/s\n",
      "global step 2060, epoch: 3, batch: 532, loss: 0.07921, auc: 0.95215, f1 score: 0.61129, speed: 0.09 step/s\n",
      "global step 2070, epoch: 3, batch: 542, loss: 0.08038, auc: 0.94951, f1 score: 0.61019, speed: 0.09 step/s\n",
      "global step 2080, epoch: 3, batch: 552, loss: 0.08892, auc: 0.95011, f1 score: 0.61148, speed: 0.08 step/s\n",
      "eval loss: 0.09099, auc: 0.94338, f1 score: 0.58115, precison: 0.58179, recall: 0.58050\n",
      "global step 2090, epoch: 3, batch: 562, loss: 0.09159, auc: 0.94457, f1 score: 0.60606, speed: 0.03 step/s\n",
      "global step 2100, epoch: 3, batch: 572, loss: 0.07685, auc: 0.94693, f1 score: 0.60226, speed: 0.08 step/s\n",
      "global step 2110, epoch: 3, batch: 582, loss: 0.09559, auc: 0.94758, f1 score: 0.60082, speed: 0.08 step/s\n",
      "global step 2120, epoch: 3, batch: 592, loss: 0.09175, auc: 0.94871, f1 score: 0.60120, speed: 0.09 step/s\n",
      "eval loss: 0.08988, auc: 0.94530, f1 score: 0.58341, precison: 0.57683, recall: 0.59014\n",
      "global step 2130, epoch: 3, batch: 602, loss: 0.08844, auc: 0.95650, f1 score: 0.63282, speed: 0.03 step/s\n",
      "global step 2140, epoch: 3, batch: 612, loss: 0.09197, auc: 0.95518, f1 score: 0.59970, speed: 0.09 step/s\n",
      "global step 2150, epoch: 3, batch: 622, loss: 0.09180, auc: 0.95152, f1 score: 0.60345, speed: 0.09 step/s\n",
      "global step 2160, epoch: 3, batch: 632, loss: 0.07297, auc: 0.95277, f1 score: 0.60862, speed: 0.08 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 08:36:18,608] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.08966, auc: 0.94390, f1 score: 0.58739, precison: 0.57696, recall: 0.59820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 08:36:18,891] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 08:36:18,893] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 2170, epoch: 3, batch: 642, loss: 0.06880, auc: 0.94672, f1 score: 0.60594, speed: 0.03 step/s\n",
      "global step 2180, epoch: 3, batch: 652, loss: 0.07442, auc: 0.94775, f1 score: 0.60460, speed: 0.09 step/s\n",
      "global step 2190, epoch: 3, batch: 662, loss: 0.09423, auc: 0.94644, f1 score: 0.59687, speed: 0.08 step/s\n",
      "global step 2200, epoch: 3, batch: 672, loss: 0.08352, auc: 0.94686, f1 score: 0.60043, speed: 0.09 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 08:47:08,923] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.08937, auc: 0.94539, f1 score: 0.58925, precison: 0.59122, recall: 0.58730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 08:47:09,212] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 08:47:09,213] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 2210, epoch: 3, batch: 682, loss: 0.07759, auc: 0.95991, f1 score: 0.60971, speed: 0.03 step/s\n",
      "global step 2220, epoch: 3, batch: 692, loss: 0.09133, auc: 0.95396, f1 score: 0.61009, speed: 0.09 step/s\n",
      "global step 2230, epoch: 3, batch: 702, loss: 0.10629, auc: 0.95305, f1 score: 0.60532, speed: 0.08 step/s\n",
      "global step 2240, epoch: 3, batch: 712, loss: 0.08878, auc: 0.95411, f1 score: 0.60307, speed: 0.09 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 08:57:50,902] [    INFO]\u001b[0m - Configuration saved in ernie_ckpt\\config.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.08904, auc: 0.94519, f1 score: 0.59322, precison: 0.57435, recall: 0.61337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-04-23 08:57:51,172] [    INFO]\u001b[0m - tokenizer config file saved in ernie_ckpt\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-04-23 08:57:51,173] [    INFO]\u001b[0m - Special tokens file saved in ernie_ckpt\\special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 2250, epoch: 3, batch: 722, loss: 0.09523, auc: 0.94936, f1 score: 0.60298, speed: 0.03 step/s\n",
      "global step 2260, epoch: 3, batch: 732, loss: 0.08483, auc: 0.94841, f1 score: 0.57862, speed: 0.09 step/s\n",
      "global step 2270, epoch: 3, batch: 742, loss: 0.08205, auc: 0.95014, f1 score: 0.58556, speed: 0.09 step/s\n",
      "global step 2280, epoch: 3, batch: 752, loss: 0.07123, auc: 0.94890, f1 score: 0.58566, speed: 0.09 step/s\n",
      "eval loss: 0.08934, auc: 0.94672, f1 score: 0.58020, precison: 0.56255, recall: 0.59899\n",
      "global step 2290, epoch: 3, batch: 762, loss: 0.08007, auc: 0.94971, f1 score: 0.59518, speed: 0.03 step/s\n"
     ]
    }
   ],
   "source": [
    "epochs = 3 # training times\n",
    "ckpt_dir = \"ernie_ckpt\" # Folder for saving model parameters during training\n",
    "\n",
    "global_step = 0  # Number of iterations\n",
    "tic_train = time.time()\n",
    "best_f1_score = 0\n",
    "\n",
    "# Model Training\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\n",
    "        input_ids, token_type_ids, labels = batch['input_ids'], batch['token_type_ids'], batch['labels']\n",
    "\n",
    "        # Calculate model output, loss function value, classification probability value, accuracy, f1 score.\n",
    "        logits = model(input_ids, token_type_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        probs = F.sigmoid(logits)\n",
    "        metric.update(probs, labels)\n",
    "        auc, f1_score, _, _ = metric.accumulate()\n",
    "\n",
    "        # Print the loss function value, accuracy, f1 score, and computation speed for each 10 iterations.\n",
    "        global_step += 1\n",
    "        if global_step % 10 == 0:\n",
    "            print(\n",
    "                \"global step %d, epoch: %d, batch: %d, loss: %.5f, auc: %.5f, f1 score: %.5f, speed: %.2f step/s\"\n",
    "                % (global_step, epoch, step, loss, auc, f1_score,\n",
    "                    10 / (time.time() - tic_train)))\n",
    "            tic_train = time.time()\n",
    "        \n",
    "        # Reverse gradient passback with updated parameters.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.clear_grad()\n",
    "        \n",
    "        # Every 40 iterations, evaluate the current trained model, save the current best model parameters and word list of the word splitter, etc.\n",
    "        if global_step % 40 == 0:\n",
    "            save_dir = ckpt_dir\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "            eval_f1_score = evaluate(model, criterion, metric, test_data_loader, label_vocab, if_return_results=False)\n",
    "            if eval_f1_score > best_f1_score:\n",
    "                best_f1_score = eval_f1_score\n",
    "                model.save_pretrained(save_dir)\n",
    "                tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation Performance Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MLbem2Gk6270",
    "outputId": "5415856c-c1b0-40b9-ac71-58cf781739b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERNIE 3.0 performance on GoEmotions micro-emotion 28 classification test set： eval loss: 0.08904, auc: 0.94519, f1 score: 0.59322, precison: 0.57435, recall: 0.61337\n"
     ]
    }
   ],
   "source": [
    "# Load the optimal parameters of the trained model.\n",
    "model.set_dict(paddle.load('ernie_ckpt/model_state.pdparams'))\n",
    "\n",
    "# Load the parameters of the previously trained model.\n",
    "# model.set_dict(paddle.load('/home/aistudio/work/model_state.pdparams'))\n",
    "\n",
    "# Model Validation.\n",
    "print(\"ERNIE 3.0 performance on GoEmotions micro-emotion 28 classification test set：\", end= \" \")\n",
    "results = evaluate(model, criterion, metric, test_data_loader, label_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 28 Multi-Label Groups of \"Micro\" Emotions Predicting Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KlKCxQYjPS3C"
   },
   "outputs": [],
   "source": [
    "# Define data loading and processing functions\n",
    "from paddlenlp.data import JiebaTokenizer, Pad, Stack, Tuple, Vocab\n",
    "def convert_example(example, tokenizer, max_seq_length=64, is_test=False):\n",
    "    qtconcat = example[\"text\"]\n",
    "    encoded_inputs = tokenizer(text=qtconcat, max_seq_len=max_seq_length)\n",
    "    input_ids = encoded_inputs[\"input_ids\"]\n",
    "    token_type_ids = encoded_inputs[\"token_type_ids\"]\n",
    "    if not is_test:\n",
    "        label = np.array([example[\"label\"]], dtype=\"int64\")\n",
    "        return input_ids, token_type_ids, label\n",
    "    else:\n",
    "        return input_ids, token_type_ids\n",
    "\n",
    "# Define the model prediction function\n",
    "def predict(model, data, tokenizer, label_vocab, batch_size=1, max_seq=64):\n",
    "    examples = []\n",
    "    # Process input data (the list form) into a format acceptable to the model\n",
    "    for text in data:\n",
    "        input_ids, segment_ids = convert_example(\n",
    "            text,\n",
    "            tokenizer,\n",
    "            max_seq_length=max_seq,\n",
    "            is_test=True)\n",
    "        examples.append((input_ids, segment_ids))\n",
    "\n",
    "    batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input id\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # segment id\n",
    "    ): fn(samples)\n",
    "\n",
    "    # Seperates data into some batches.\n",
    "    batches = []\n",
    "    one_batch = []\n",
    "    for example in examples:\n",
    "        one_batch.append(example)\n",
    "        if len(one_batch) == batch_size:\n",
    "            batches.append(one_batch)\n",
    "            one_batch = []\n",
    "    if one_batch:\n",
    "        # The last batch whose size is less than the config batch_size setting.\n",
    "        batches.append(one_batch)\n",
    "\n",
    "    results = []\n",
    "    model.eval()\n",
    "    for batch in batches:\n",
    "        input_ids, segment_ids = batchify_fn(batch)\n",
    "        input_ids = paddle.to_tensor(input_ids)\n",
    "        segment_ids = paddle.to_tensor(segment_ids)\n",
    "        logits = model(input_ids, segment_ids)\n",
    "        probs = F.sigmoid(logits)\n",
    "        probs = probs.tolist()\n",
    "        # The results were processed by selecting the sentiment categories with probability greater than 0.5\n",
    "        for prob in probs:\n",
    "            result = []\n",
    "            for c, pred in enumerate(prob):\n",
    "                if pred > 0.5:\n",
    "                    result.append(label_vocab[c])\n",
    "            results.append(','.join(result))\n",
    "    return results  # Return the predeicted results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3W2OfqsBRfB1",
    "outputId": "02108fee-776c-4de9-c907-9a077c33e4b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: You do a great job! \t Labels: admiration\n",
      "Text: Lets have fun \t Labels: joy\n",
      "Text: You shut your mouth \t Labels: anger\n",
      "Text: You are so annoyed \t Labels: anger\n",
      "Text: You are allowed to do this \t Labels: neutral\n",
      "Text: Are you feeling well? \t Labels: curiosity\n",
      "Text: This problem is so hard and I cannot solve this problem \t Labels: \n",
      "Text: Why would I do that? \t Labels: curiosity\n",
      "Text: I want this gift so much \t Labels: desire\n",
      "Text: I am very disappointed by everything you have done to me \t Labels: disappointment\n",
      "Text: You are not admitted to the college. \t Labels: neutral\n",
      "Text: Thats absolutely disgusting. \t Labels: disgust\n",
      "Text: Thats so embarrassing. \t Labels: embarrassment\n",
      "Text: I am so excited \t Labels: excitement\n",
      "Text: I am so scared of skydiving \t Labels: fear\n",
      "Text: Thank you. \t Labels: gratitude\n",
      "Text: My grandpa passed away \t Labels: \n",
      "Text: Happy Birthday \t Labels: joy\n",
      "Text: I love you so much \t Labels: love\n",
      "Text: I am so nervous. \t Labels: \n",
      "Text: It is just so so. \t Labels: neutral\n",
      "Text: Successful people only focus on giving their best effort. \t Labels: \n",
      "Text: I am so proud of you. \t Labels: admiration\n",
      "Text: Thank you for letting me realizing this rule. \t Labels: gratitude\n",
      "Text: You are doing better than you think you are \t Labels: \n",
      "Text: I am guilty. \t Labels: remorse\n",
      "Text: I am so sad. \t Labels: sadness\n",
      "Text: I am so surprised that you made it. \t Labels: surprise\n"
     ]
    }
   ],
   "source": [
    "# Define the text data to be subjected to micro-sentiment analysis\n",
    "data = [\n",
    "    # 0 admiration\n",
    "    {\"text\": 'You do a great job!'},\n",
    "    # 1 amusement\n",
    "    {\"text\": 'Lets have fun'},\n",
    "    # 2 anger\n",
    "    {\"text\":\"You shut your mouth\"},\n",
    "    # 3 annoyance\n",
    "    {\"text\": 'You are so annoyed'},\n",
    "    # 4 approval\n",
    "    {\"text\": 'You are allowed to do this'},\n",
    "    # 5 caring & # 7 Curiosity\n",
    "    {\"text\": 'Are you feeling well?'},\n",
    "    # 6 confusion\n",
    "    {\"text\": 'This problem is so hard and I cannot solve this problem'},\n",
    "    # 7 curiosity\n",
    "    {\"text\":'Why would I do that?'},\n",
    "    # 8 desire\n",
    "    {\"text\": 'I want this gift so much'},\n",
    "    # 9 disappointment\n",
    "    {\"text\": 'I am very disappointed by everything you have done to me'},\n",
    "    # 10 disapproval\n",
    "    {\"text\": 'You are not admitted to the college.'},\n",
    "    # 11 disgust\n",
    "    {\"text\": 'Thats absolutely disgusting.'},\n",
    "    # 12 embarrassment\n",
    "    {\"text\": 'Thats so embarrassing.'},\n",
    "    # 13 excitement\n",
    "    {\"text\": 'I am so excited'},\n",
    "    # 14 fear\n",
    "    {\"text\": 'I am so scared of skydiving'},\n",
    "    # 15 gratitude\n",
    "    {\"text\":\"Thank you.\"},\n",
    "    # 16 grief\n",
    "    {\"text\": 'My grandpa passed away'},\n",
    "    # 17 joy\n",
    "    {\"text\": 'Happy Birthday'},\n",
    "    # 18 love\n",
    "    {\"text\": 'I love you so much'},\n",
    "    # 19 nervousness\n",
    "    {\"text\": 'I am so nervous.'},\n",
    "    # 20 neutral\n",
    "    {\"text\": 'It is just so so.'},\n",
    "    # 21 optimism\n",
    "    {\"text\": 'Successful people only focus on giving their best effort.'},\n",
    "    # 22 pride\n",
    "    {\"text\": 'I am so proud of you.'},\n",
    "    # 23 realization\n",
    "    {\"text\": 'Thank you for letting me realizing this rule.'},\n",
    "    # 24 relief \n",
    "    {\"text\": 'You are doing better than you think you are'},\n",
    "    # 25 remorse\n",
    "    {\"text\": 'I am guilty.'},\n",
    "    # 26 sadness\n",
    "    {\"text\": 'I am so sad.'},\n",
    "    # 27 surprise\n",
    "    {\"text\": 'I am so surprised that you made it.'},\n",
    "    \n",
    "]\n",
    "\n",
    "# Model Prediction\n",
    "labels =  predict(model, data, tokenizer, label_vocab, batch_size=1)\n",
    "\n",
    "# Output of predicted results\n",
    "for idx, text in enumerate(data):\n",
    "    print('Text: {} \\t Labels: {}'.format(text['text'], labels[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9DDfiSCsA2ur"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "23288bf360984ed182be7d6d84841716": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "290bc213ab9e48898ebbc8c4e31fe36e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36f1a68b633d45c08eb1fc80d282838d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f2a18e109734e53bd330eceb3d79712": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5269406c713340ceb8f6bd40782769d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a0a3265f4fc40acac71a85fc3a29c97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23288bf360984ed182be7d6d84841716",
      "max": 327709220,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ce8f3f6b29f74c94aedc579412a4aa5e",
      "value": 327709220
     }
    },
    "5f302f73d14d4aa68d48a8d06c4d8717": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5269406c713340ceb8f6bd40782769d7",
      "placeholder": "​",
      "style": "IPY_MODEL_74a0ab1a08ee49cba9f797176a92b2f2",
      "value": " 313M/313M [00:19&lt;00:00, 30.8MB/s]"
     }
    },
    "62335350a40e41d1b1fe80e221baa984": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6bcd679979a14b92ad7bd28b58ed883f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ac8d5f80a0324c538908ab32974f9b6a",
       "IPY_MODEL_751c62037368473dac02b36dd1c0b05f",
       "IPY_MODEL_6e257f83475345ddbed64f81dccfb309"
      ],
      "layout": "IPY_MODEL_290bc213ab9e48898ebbc8c4e31fe36e"
     }
    },
    "6d0f814a0b03493abe1044ef14bf15dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e257f83475345ddbed64f81dccfb309": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef7240d1bccd40ebbd05455bb4c994bf",
      "placeholder": "​",
      "style": "IPY_MODEL_d79c404107ff4d16a3945df9b74ec5d3",
      "value": " 182k/182k [00:00&lt;00:00, 490kB/s]"
     }
    },
    "74a0ab1a08ee49cba9f797176a92b2f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "751c62037368473dac02b36dd1c0b05f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36f1a68b633d45c08eb1fc80d282838d",
      "max": 186807,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_62335350a40e41d1b1fe80e221baa984",
      "value": 186807
     }
    },
    "8f0bb537306940a192c374f5458f3c99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d6f5d91a6c34eb2be6c43b9d77316c2",
       "IPY_MODEL_5a0a3265f4fc40acac71a85fc3a29c97",
       "IPY_MODEL_5f302f73d14d4aa68d48a8d06c4d8717"
      ],
      "layout": "IPY_MODEL_3f2a18e109734e53bd330eceb3d79712"
     }
    },
    "94803e83cafa4a50bb2d8a3fbaf73274": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d6f5d91a6c34eb2be6c43b9d77316c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0b878e93f3b4a2a9b3de57d15ab55e1",
      "placeholder": "​",
      "style": "IPY_MODEL_6d0f814a0b03493abe1044ef14bf15dc",
      "value": "100%"
     }
    },
    "ac8d5f80a0324c538908ab32974f9b6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94803e83cafa4a50bb2d8a3fbaf73274",
      "placeholder": "​",
      "style": "IPY_MODEL_faa019ca3caa4a4e809a1612319ac503",
      "value": "100%"
     }
    },
    "ce8f3f6b29f74c94aedc579412a4aa5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d0b878e93f3b4a2a9b3de57d15ab55e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d79c404107ff4d16a3945df9b74ec5d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef7240d1bccd40ebbd05455bb4c994bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "faa019ca3caa4a4e809a1612319ac503": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
